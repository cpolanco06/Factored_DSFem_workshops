{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de APIs con FastAPI\n",
    "El objetivo de esta sección es crear una API para consumir uno de los modelos que se generaron en el workshop anterior \"scikit-learn y MLFlow\". De igual forma, se empleará el pipeline de preprocesamiento de datos que se creó en el workshop anterior  \"Pipelines en scikit-learn\". \n",
    "\n",
    "Antes de arrancar, aseguremosnos de tener las siguientes dependencias en nuestro entorno de desarrollo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dill==0.3.3\n",
    "scikit-learn==0.24.1\n",
    "python-multipart==0.0.5\n",
    "numpy==1.21.0\n",
    "pandas==1.2.5\n",
    "matplotlib==3.4.2\n",
    "mlflow==1.20.2\n",
    "seaborn==0.11.1\n",
    "fastapi==0.68.1\n",
    "uvicorn==0.15.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "dill.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn\n",
    "seaborn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.68.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastapi\n",
    "fastapi.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uvicorn\n",
    "uvicorn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multipart\n",
    "multipart.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elección del modelo que se va a desplegar\n",
    "Antes de iniciar el código de nuestra primer API usando FastAPI, recordemos el final del workshop anterior, donde exportamos el pipeline de preprocesamiento de los datos y el modelo en objetos \".dill\".\n",
    "\n",
    "Creamos un contexto usando `open()` y usamos la función `dill.dump()` para guardar nuestro flujo de preprocesamiento en disco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import dill\n",
    "dill.settings['recurse'] = True\n",
    "dill.dump(full_pipeline, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('./preprocesser.pkl', 'wb') as f:\n",
    "    dill.dump(full_pipeline, f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un contexto usando `open()` y usamos la función `dill.dump()` para guardar nuestro modelo en disco. El modelo que usaremos es la Regresión Lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with open('./lr_model.pkl', 'wb') as f:\n",
    "    dill.dump(model,f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, también necesitamos un archivo llamado \"requirements.txt\".\n",
    "\n",
    "El archivo \"requirements.txt\" tiene los requerimientos para la API, que se pueden observar a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dill==0.3.3\n",
    "scikit-learn==0.24.1\n",
    "python-multipart==0.0.5\n",
    "numpy==1.21.0\n",
    "pandas==1.2.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a elegir un lugar en nuestro directorio para poner todos los archivos relacionados al despliegue del modelo. A ésta carpeta la podemos nombrar \"despliegue\" y los primeros archivos que almacenaremos acá serán el pipeline de procesamiento \"preprocesser.pkl\", el script \"transformes.py\" el cual es usado por el preprocesador, el modelo Regresión Linear 'lr_model.dill' y el archivo \"requirements.txt\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "despliegue\n",
    "├── preprocesser.pkl\n",
    "├── lr_model.pkl\n",
    "├── transformers.py\n",
    "└── requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar dependencias, Preprocesador y Modelo\n",
    "1. Importaremos las dependencias en la ruta de despliegue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r /despliegue/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Vamos a crear un script en nuestra carpeta de despliegue llamado `main.py`. Y vamos a importar las  dependencias necesariar para usar FastAPI, el preprocesador y el modelo. También vamos a crear nuestra API, la cual tendrá el nombre de \"Taxi Trips Duration Predictor\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "from fastapi import FastAPI, File\n",
    "from fastapi.responses import JSONResponse\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from transformers import TransformerFechas, TransformerDistancia, TransformerVelocidad\n",
    "\n",
    "app = FastAPI(title=\"Taxi Trips Duration Predictor\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Ahora vamos a importar el modelo y el preprocesador que creamos y exportamos en la sesión anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# import the preprocessor\n",
    "with open(\"preprocesser.pkl\", \"rb\") as f:\n",
    "    preprocessor = dill.load(f)\n",
    "# import the model\n",
    "with open(\"lr_model.pkl\", \"rb\") as f:\n",
    "    model = dill.load(f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solicitudes y Respuestas\n",
    "Las API funcionan mediante “solicitudes” y “respuestas”. Cuando una API solicita información de una aplicación web o un servidor web, recibirá una respuesta. \n",
    "\n",
    "Nuestra API tendrá la funcionalidad de recibir \"solicitudes\" con los datos de los features que requiere el modelo, luego la lógica del negocio procesará los datos y finalmente la API devolverá una \"respuesta\" con la predicción del modelo. En este caso, la lógica del negocio consiste en el pipeline de preprocesamiento y el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puntos finales o \"Endpoints\" \n",
    "El lugar al que las API envían solicitudes y donde reside el recurso se denomina \"endpoint\".\n",
    "\n",
    "Cuando una API interactúa con otro sistema, los puntos de contacto de esta comunicación se consideran puntos finales. Para las API, un punto final puede incluir una URL de un servidor o servicio. Cada punto final es la ubicación desde la que las API pueden acceder a los recursos que necesitan para llevar a cabo su función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer Endpoint: Get Endpoint\n",
    "Las solicitudes GET son los métodos más comunes y más utilizados en API y sitios web. El método GET se utiliza para recuperar datos de un servidor en el recurso especificado. Por ejemplo, supongamos que tiene una API con un punto final /users. Hacer una solicitud GET a ese punto final debería devolver una lista de todos los usuarios disponibles.\n",
    "\n",
    "`GET` es un método que puede recibir parámetros a través de parámetros \"path\" o parámetros \"query\":\n",
    "\n",
    "- `Path Parameters`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.get(\"/{}\", response_class=JSONResponse)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes revisar la documentación de `Path Parameters` en FastAPI [acá](https://fastapi.tiangolo.com/tutorial/path-params/).\n",
    "\n",
    "- `Query Parameters`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.get(\"/\", response_class=JSONResponse)\n",
    "def get_funct(\n",
    "    vendor_id: int,\n",
    "    pickup_datetime: str,\n",
    "    passenger_count: int,\n",
    "    pickup_longitude: float,\n",
    "    pickup_latitude: float,\n",
    "    dropoff_longitude: float,\n",
    "    dropoff_latitude: float,\n",
    "    pickup_borough: str,\n",
    "    dropoff_borough: str,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los `Query Parameters`, los parámetros se definen al interior de la función `get_func()`.\n",
    "\n",
    "Puedes revisar la documentación de `Query Parameters` en FastAPI [acá](https://fastapi.tiangolo.com/tutorial/query-params/).\n",
    "\n",
    "En el presente ejemplo nuestro método `GET` recibirá los parámetros con la convención de query parameters y retornará la respuesta de la predicción en un JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "from fastapi import FastAPI, File\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "from transformers import TransformerFechas, TransformerDistancia, TransformerVelocidad\n",
    "\n",
    "app = FastAPI(title=\"Taxi Trips Duration Predictor\")\n",
    "\n",
    "# import the preprocessor\n",
    "with open(\"preprocesser.pkl\", \"rb\") as f:\n",
    "    preprocessor = dill.load(f)\n",
    "# import the model\n",
    "with open(\"lr_model.pkl\", \"rb\") as f:\n",
    "    model = dill.load(f)\n",
    "\n",
    "\n",
    "@app.get(\"/\", response_class=JSONResponse)\n",
    "def get_funct(\n",
    "    vendor_id: int,\n",
    "    pickup_datetime: str,\n",
    "    passenger_count: int,\n",
    "    pickup_longitude: float,\n",
    "    pickup_latitude: float,\n",
    "    dropoff_longitude: float,\n",
    "    dropoff_latitude: float,\n",
    "    pickup_borough: str,\n",
    "    dropoff_borough: str,\n",
    "):\n",
    "    \"\"\"Serves predictions given query parameters specifying the taxi trip's\n",
    "    features from a single example.\n",
    "\n",
    "    Args:\n",
    "        vendor_id (int): a code indicating the provider associated with the trip record\n",
    "        pickup_datetime (str): date and time when the meter was engaged\n",
    "        passenger_count (float): the number of passengers in the vehicle\n",
    "        (driver entered value)\n",
    "        pickup_longitude (float): the longitude where the meter was engaged\n",
    "        pickup_latitude (float): the latitude where the meter was engaged\n",
    "        dropoff_longitude (float): the longitude where the meter was disengaged\n",
    "        dropoff_latitude (float): the latitude where the meter was disengaged\n",
    "        pickup_borough (str): the borough where the meter was engaged\n",
    "        dropoff_borough (str): the borough where the meter was disengaged\n",
    "\n",
    "    Returns:\n",
    "        [JSON]: model prediction for the single example given\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                vendor_id,\n",
    "                pickup_datetime,\n",
    "                passenger_count,\n",
    "                pickup_longitude,\n",
    "                pickup_latitude,\n",
    "                dropoff_longitude,\n",
    "                dropoff_latitude,\n",
    "                pickup_borough,\n",
    "                dropoff_borough,\n",
    "            ]\n",
    "        ],\n",
    "        columns=[\n",
    "            \"vendor_id\",\n",
    "            \"pickup_datetime\",\n",
    "            \"passenger_count\",\n",
    "            \"pickup_longitude\",\n",
    "            \"pickup_latitude\",\n",
    "            \"dropoff_longitude\",\n",
    "            \"dropoff_latitude\",\n",
    "            \"pickup_borough\",\n",
    "            \"dropoff_borough\",\n",
    "        ],\n",
    "    )\n",
    "    prediction = model.predict(preprocessor.transform(df))\n",
    "    return {\n",
    "        \"features\": {\n",
    "            \"vendor_id\": vendor_id,\n",
    "            \"pickup_datetime\": pickup_datetime,\n",
    "            \"passenger_count\": passenger_count,\n",
    "            \"pickup_longitude\": pickup_longitude,\n",
    "            \"pickup_latitude\": pickup_latitude,\n",
    "            \"dropoff_longitude\": dropoff_longitude,\n",
    "            \"dropoff_latitude\": dropoff_latitude,\n",
    "            \"pickup_borough\": pickup_borough,\n",
    "            \"dropoff_borough\": dropoff_borough,\n",
    "        },\n",
    "        \"prediction\": list(prediction)[0],\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    # For local development:\n",
    "    uvicorn.run(\"main:app\", port=3000, reload=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos el main de nuestra API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    # For local development:\n",
    "    uvicorn.run(\"main:app\", port=3000, reload=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reload=True` permite que cada vez que se guarde el archivo main.py, la API se actualice automáticamente, sin necesidad de cerrar la API y volverla a reiniciar cada vez que se haga un cambio. Esta es una funcionalidad muy útil durante la etapa de desarrollo de la API, no es recomendable tenerla en la etapa de despligue. \n",
    "\n",
    "Así es como se debe ver ahora la estructura de la carpeta `despliegue`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "despliegue\n",
    "├── preprocesser.pkl\n",
    "├── lr_model.pkl\n",
    "├── transformers.py\n",
    "├── main.py\n",
    "└── requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación debemos ir a la terminal, ubicarnos en la carpeta \"despliegue\" y correr el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python main.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la terminal obtendremos una salida así:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡A continuación viene la mejor parte! ¡Vamos a probar nuestra API!\n",
    "\n",
    "Así que ahora ve a tu buscador preferido, puede ser Chrome, Safari, ojalá no Internet Explorer 😁  si quieres acabar este workpshop hoy 🤭  \n",
    "\n",
    "Una vez en el buscador, coloca esta dirección [`http://127.0.0.1:3000`](http://127.0.0.1:3000)\n",
    "\n",
    "Si nos quedamos en esta dirección podríamos pasar los features del modelo editando la URL directamente, pero esto sería engorroso. Afortunadamente FastAPI tiene por default un Front que podemos usar con cualquiera de nuestras APIs. Así que sólo debemos hacer un cambio en la URL:\n",
    "\n",
    "[`http://127.0.0.1:3000/docs`](http://127.0.0.1:3000/docs)\n",
    "\n",
    "Ahora deberías ver algo así en el buscador:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image4.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, presionando \"Try it out\" puedes rellenar para cada feature su valor correspondiente, de esta forma el modelo recibe los datos que va a preprocesar y luego el modelo podrá generar su predicción y enviarla como respuesta!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #1**\n",
    "\n",
    "Try out! Ensayar el método GET con features reales:\n",
    "- vendor_id: 2\n",
    "- pickup_datetime: 2016-03-14 17:24:55\n",
    "- passenger_count: 1\n",
    "- pickup_longitude: -73.9821548462\n",
    "- pickup_latitude: 40.7679367065\n",
    "- dropoff_longitude: -73.964630127\n",
    "- dropoff_latitude: 40.7656021118\n",
    "- pickup_borough: Manhattan\n",
    "- dropoff_borough: Manhattan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final debes obtener el codigo de respuesta éxitosa, es decir 200, y la predicción del modelo. Se debe ver más o menos así:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image6.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Endpoint: Post Endpoint\n",
    "En los servicios web, las solicitudes POST se utilizan para enviar datos al servidor API para crear o actualizar un recurso. Los datos enviados al servidor se almacenan en el cuerpo de la solicitud HTTP.\n",
    "\n",
    "El ejemplo más simple es un formulario de contacto en un sitio web. Cuando completas las entradas en un formulario y presionas Enviar, esos datos se colocan en el cuerpo de respuesta de la solicitud y se envían al servidor. Puede ser JSON, XML o parámetros de consulta (query parameters).\n",
    "\n",
    "En este caso, nos gustaría que nuestro método POST reciba un JSON y retorne un JSON.\n",
    "\n",
    "`BaseModel`  de [pydantic](https://pydantic-docs.helpmanual.io/) es una clase de la cuál vamos a heredar para crear las especificaciones del JSON que va a ingresar en nuestro Endpoint. Por eso la debemos agregar a nuestras dependencias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "from fastapi import FastAPI, File\n",
    "from fastapi.responses import JSONResponse, StreamingResponse\n",
    "from pydantic import BaseModel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear la clase TaxiTrip, que hereda de BaseModel. TaxiTrip va a ser un objeto con 9 parámetros que describen un viaje en taxi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class TaxiTrip(BaseModel):\n",
    "    vendor_id: int\n",
    "    pickup_datetime: str\n",
    "    passenger_count: float\n",
    "    pickup_longitude: float\n",
    "    pickup_latitude: float\n",
    "    dropoff_longitude: float\n",
    "    dropoff_latitude: float\n",
    "    pickup_borough: str\n",
    "    dropoff_borough: str\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, en nuestro `POST` endpoint vamos a definir que el parámetro que entra es un taxitrip de tipo TaxiTrip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.post(\"/json\", response_class=JSONResponse)\n",
    "def post_json(taxitrip: TaxiTrip):\n",
    "    \"\"\"Serves predictions given a request body specifying the taxis trip's features\n",
    "    from a single example.\n",
    "\n",
    "    Args:\n",
    "        taxitrip (TaxiTrip): request body of type `TaxiTrip` with the\n",
    "        attributes: vendor_id, pickup_datetime, passenger_count, pickup_longitude,\n",
    "        pickup_latitude, dropoff_longitude, dropoff_latitude, pickup_borough and\n",
    "        dropoff_borough\n",
    "\n",
    "    Returns:\n",
    "        [JSON]: model prediction for the single example given\n",
    "    \"\"\"\n",
    "    vendor_id = taxitrip.vendor_id\n",
    "    pickup_datetime = taxitrip.pickup_datetime\n",
    "    passenger_count = taxitrip.passenger_count\n",
    "    pickup_longitude = taxitrip.pickup_longitude\n",
    "    pickup_latitude = taxitrip.pickup_latitude\n",
    "    dropoff_longitude = taxitrip.dropoff_longitude\n",
    "    dropoff_latitude = taxitrip.dropoff_latitude\n",
    "    pickup_borough = taxitrip.pickup_borough\n",
    "    dropoff_borough = taxitrip.dropoff_borough\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                vendor_id,\n",
    "                pickup_datetime,\n",
    "                passenger_count,\n",
    "                pickup_longitude,\n",
    "                pickup_latitude,\n",
    "                dropoff_longitude,\n",
    "                dropoff_latitude,\n",
    "                pickup_borough,\n",
    "                dropoff_borough,\n",
    "            ]\n",
    "        ],\n",
    "        columns=[\n",
    "            \"vendor_id\",\n",
    "            \"pickup_datetime\",\n",
    "            \"passenger_count\",\n",
    "            \"pickup_longitude\",\n",
    "            \"pickup_latitude\",\n",
    "            \"dropoff_longitude\",\n",
    "            \"dropoff_latitude\",\n",
    "            \"pickup_borough\",\n",
    "            \"dropoff_borough\",\n",
    "        ],\n",
    "    )\n",
    "    prediction = model.predict(preprocessor.transform(df))\n",
    "    return {\n",
    "        \"features\": {\n",
    "            \"vendor_id\": vendor_id,\n",
    "            \"pickup_datetime\": pickup_datetime,\n",
    "            \"passenger_count\": passenger_count,\n",
    "            \"pickup_longitude\": pickup_longitude,\n",
    "            \"pickup_latitude\": pickup_latitude,\n",
    "            \"dropoff_longitude\": dropoff_longitude,\n",
    "            \"dropoff_latitude\": dropoff_latitude,\n",
    "            \"pickup_borough\": pickup_borough,\n",
    "            \"dropoff_borough\": dropoff_borough,\n",
    "        },\n",
    "        \"prediction\": list(prediction)[0],\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, guardamos los cambios en el archivo `main.py` y recargamos la página:\n",
    "\n",
    "[`http://127.0.0.1:3000/docs`](http://127.0.0.1:3000/docs)\n",
    "\n",
    "Como podremos observar, ya nuestro `POST` Endpoint está listo para usar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image7.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #2**\n",
    "\n",
    "Try out! Ensayar el método POST con features reales:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"vendor_id\": 2,\n",
    "  \"pickup_datetime\": \"2016-03-14 17:24:55\",\n",
    "  \"passenger_count\": 1,\n",
    "  \"pickup_longitude\": -73.9821548462,\n",
    "  \"pickup_latitude\": 40.7679367065,\n",
    "  \"dropoff_longitude\": -73.964630127,\n",
    "  \"dropoff_latitude\": 40.7656021118,\n",
    "  \"pickup_borough\": \"Manhattan\",\n",
    "  \"dropoff_borough\": \"Manhattan\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final debes obtener el codigo de respuesta éxitosa, es decir 200 y la predicción del modelo. Se debe ver más o menos así:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image8.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercer Endpoint: POST Endpoint\n",
    "Este último Endpoint será diferente al anterior ya que recibirá como entrada un archivo y devolverá un archivo a su vez. Por esto, debemos importar otro tipo de respuesta de FastAPI en nuestras dependencias, el `StreamingResponse`.\n",
    "\n",
    "Por otro lado, nuestro método `POST` va a recibir un parámetro de tipo `File`, así que también lo debemos importar de la librería `fastapi`.\n",
    "\n",
    "Además, debemos traer la clase `BytesIO` de la librería `io`, la cual toma un objeto bytes que está en memoria en python e imita el comportamiento de un archivo, de lo que Python considera un objeto tipo archivo, el cual tiene métodos de \"read\" y \"write\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "from fastapi import FastAPI, File\n",
    "from fastapi.responses import JSONResponse, StreamingResponse\n",
    "from pydantic import BaseModel\n",
    "from io import BytesIO\n",
    "\n",
    "from transformers import TransformerFechas, TransformerDistancia, TransformerVelocidad\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StreamingResponse` es muy útil ya que no guarda los archivos en disco sino que en el Browser recibe el archivo. De esta forma ahorramos espacio en el disco, evitamos las operaciones en disco y las hacemos en memoria, lo cual es mucho más rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.post(\"/file\", response_class=StreamingResponse)\n",
    "def post_file(file: bytes = File(...)):\n",
    "    \"\"\"Serves predictions given a CSV file with no header and seven columns\n",
    "    specifying each taxi trip's features in the order vendor_id, pickup_datetime,\n",
    "    passenger_count, pickup_longitude,pickup_latitude, dropoff_longitude and\n",
    "    dropoff_latitude, pickup_borough and dropoff_borough\n",
    "\n",
    "    Args:\n",
    "        file (bytes, optional): bytes from a CSV file as described above.\n",
    "         Defaults to File(...), but to receive a file is required.\n",
    "\n",
    "    Returns:\n",
    "        [StreamingResponse]: Returns a streaming response with a new CSV file that contains\n",
    "        a column with the predictions.\n",
    "    \"\"\"\n",
    "    # Decode the bytes as text and split the lines:\n",
    "    input_lines = file.decode().splitlines()\n",
    "\n",
    "    # Split each line as a list of the three features:\n",
    "    X = [p.split(\",\") for p in input_lines]\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        vendor_id = int(x[0])\n",
    "        pickup_datetime = str(x[1])\n",
    "        passenger_count = float(x[2])\n",
    "        pickup_longitude = float(x[3])\n",
    "        pickup_latitude = float(x[4])\n",
    "        dropoff_longitude = float(x[5])\n",
    "        dropoff_latitude = float(x[6])\n",
    "        pickup_borough = str(x[7])\n",
    "        dropoff_borough = str(x[8])\n",
    "        df = pd.DataFrame(\n",
    "            [\n",
    "                [\n",
    "                    vendor_id,\n",
    "                    pickup_datetime,\n",
    "                    passenger_count,\n",
    "                    pickup_longitude,\n",
    "                    pickup_latitude,\n",
    "                    dropoff_longitude,\n",
    "                    dropoff_latitude,\n",
    "                    pickup_borough,\n",
    "                    dropoff_borough,\n",
    "                ]\n",
    "            ],\n",
    "            columns=[\n",
    "                \"vendor_id\",\n",
    "                \"pickup_datetime\",\n",
    "                \"passenger_count\",\n",
    "                \"pickup_longitude\",\n",
    "                \"pickup_latitude\",\n",
    "                \"dropoff_longitude\",\n",
    "                \"dropoff_latitude\",\n",
    "                \"pickup_borough\",\n",
    "                \"dropoff_borough\",\n",
    "            ],\n",
    "        )\n",
    "        # Get predictions for each taxi trip:\n",
    "        prediction = model.predict(preprocessor.transform(df))\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # Append the prediction to each input line:\n",
    "    output = [line + \",\" + str(pred[0]) for line, pred in zip(input_lines, predictions)]\n",
    "    # Join the output as a single string:\n",
    "    output = \"\\n\".join(output)\n",
    "    # Encode output as bytes:\n",
    "    output = output.encode()\n",
    "\n",
    "    # The kind is text, the extension is csv\n",
    "    return StreamingResponse(\n",
    "        BytesIO(output),\n",
    "        media_type=\"text/csv\",\n",
    "        headers={\"Content-Disposition\": 'attachment;filename=\"prediction.csv\"'},\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, guardamos los cambios en el archivo main.py y recargamos la página:\n",
    "\n",
    "[`http://127.0.0.1:3000/docs`](http://127.0.0.1:3000/docs)\n",
    "\n",
    "Como podremos observar, ya nuestro tercer Endpoint (POST) está listo para usar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tercer endpoint recibe un archivo .CSV con diferentes ejemplos, te reto a generar las predicciones de los ejemplos en el siguiente archivo:\n",
    "\n",
    "`example.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #3**\n",
    "\n",
    "Try out! Ensayar el método POST con features reales del archivo CSV previo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final debes obtener el codigo de respuesta éxitosa, es decir 200 y la predicción del modelo. Se debe ver más o menos así:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, desde el buscador podemos descargar un archivo que contendrá los features de cada ejemplo y sus respectivas predicciones. Ese archivo se llamará \"prediction.csv\" y su contenido se debe ver así:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image11.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar la predicción fue la misma para ambos ejemplos, esto nos indica que la Regresión Lineal no es un modelo muy robusto. Para este workshop se decidió usar la Regresión Lineal por simplicidad y por ser un modelo liviano, pero lo recomendable es siempre elegir el mejor modelo que se haya encontrada en la etapa de experimentación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Despliegue de Software con Docker\n",
    "En esta sección vamos desplegar nuestra API usando Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es un Contenedor de Docker?\n",
    "Es una herramienta que nos permite aislar el entorno de cualquier software que queramos implementar.\n",
    "\n",
    "Si desarrollo una pieza de software en mi entorno, con ciertas dependencias y versiones de las bibliotecas que uso en un sistema operativo específico, entonces, lo que hice en mi PC, podría no funcionar en otro PC. \n",
    "\n",
    "El contenedor de Docker es como un mini computador, está asociado al concepto de máquinas virtuales. Sin embargo, las máquinas virtuales asignan una gran cantidad de recursos, incluso si la aplicación no se está utilizando. \n",
    "\n",
    "Cuando el contenedor de Docker no usa recursos, no bloquea el host para usarlos, por lo que es más eficiente que las máquinas virtuales.\n",
    "\n",
    "El contenedor de Docker tiene un sistema operativo específico, normalmente Linux. La aplicación se ejecuta allí, de tal manera que no importa quién la ejecute o en qué computadora, el sistema operativo y las bibliotecas operativo son los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es una Imagen de Docker?\n",
    "Es como un molde de donde se crean los contenedores.\n",
    "\n",
    "Un contenedor es una instanciación específica de la imagen de Docker, que puede ejecutarse en cualquier host que tenga la aplicación de escritorio de Docker (Docker desktop).\n",
    "\n",
    "Para seleccionar una imagen de Docker, debemos partir de una imagen que ya tenga algunas de nuestras dependencias. Por ejemplo, en este caso nos interesará una imagen que ya tenga python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Dónde encontramos las imágenes de Docker?\n",
    "Dockerhub es el repositorio oficial de imágenes de Docker\n",
    "\n",
    "[Docker Hub Container Image Library | App Containerization](https://hub.docker.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src='../imgs/image12.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora busquemos una imagen que ya contenga FastAPI usando las palabras clave “tiangolo fastapi”:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image13.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera imagen que podemos ver, `tiangolo/uvicorn-gunicorn-fastapi` es lo más cercano a una “imagen oficial de Docker de fastapi” que encontraremos, ya que fue desarrollada por tiangolo, el creador de fastapi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es un Dockerfile?\n",
    "Una imagen de Docker es un molde para crear un contenedor de Docker, y ¿cómo creamos ese molde? Con un Dockerfile.\n",
    "\n",
    "Un Dockerfile es la receta para crear el molde.\n",
    "\n",
    "Un Dockerfile es un archivo con un conjunto de pasos que le dicen a Docker cómo crear esa imagen.\n",
    "\n",
    "Vamos a crear un archivo llamado Dockerfile, en la misma carpeta donde tenemos nuestra aplicación y luego vamos a escribir algunos comandos en él.\n",
    "\n",
    "El directorio debería verse así ahora mismo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "despliegue\n",
    "├── preprocesser.pkl\n",
    "├── lr_model.pkl\n",
    "├── transformers.py\n",
    "├── main.py\n",
    "├── Dockerfile\n",
    "└── requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comandos del Dockerfile\n",
    "`FROM` → aquí especificamos en qué imagen nos basamos para crear nuestra imagen propia.\n",
    "\n",
    "Ya seleccionamos la imagen base `tiangolo/uvicorn-gunicorn-fastapi` Pero también tenemos que seleccionar una versión o una etiqueta en la sección `Tags`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image14.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y vamos a seleccionar la etiqueta `python3.9-slim`, que es una versión liviana de python.\n",
    "\n",
    "Entonces, el comando `FROM` se verá así:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9-slim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`WORKDIR` → Para especificar nuestro directorio de trabajo. Ya está especificado en la imagen de Docker pero es bueno saber en que directorio de trabajo estamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "WORKDIR /app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EXPOSE` → El puerto que vamos a exponer. Ya está especificado en la imagen de Docker pero es bueno saber qué puerto está expuesto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "EXPOSE 80\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el comando `COPY` para traer el archivo `requirements.txt` ubicado en la carpeta donde se encuentra el `Dockerfile`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "COPY requirements.txt .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run` → Queremos incluir algunas dependencias\n",
    "\n",
    "`-r` →  ejecutar `pip -r`  permite recibir una ruta con una lista de dependencias que se requieran instalar. Es muy útil instalarlos todos a la vez.\n",
    "\n",
    "No se recomienda tener varios comandos RUN en el dockerfile, es mejor tener solo un comando RUN.\n",
    "\n",
    "`RUN` se utiliza para instalar dependencias normalmente. Para ejecutar cualquier cosa que necesitemos poner en nuestra imagen de Docker. Lo ejecutamos y termina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RUN [\"pip\", \"install\", \"-r\",\"./requirements.txt\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`COPY` → Necesitamos copiar cosas de nuestro host (de nuestra máquina) a la imagen de Docker. Se van a copiar en el contenedor de Docker cuando iniciemos la imagen para crear el contenedor. Esto se puede hacer con paths relativos.\n",
    "\n",
    "Lo que sea que esté dentro de mi carpeta de `despliegue` es lo que quiero que esté en mi directorio de trabajo en el contenedor de Docker o la imagen de Docker.\n",
    "\n",
    "`COPY .` → El 1er punto representa la carpeta donde está el Dockerfile. Entonces, en este caso, se refiere a la carpeta despliegue.\n",
    "\n",
    "`COPY . .` → El 2ndo punto se refiere al directorio de trabajo dentro de la imagen de Docker.\n",
    "\n",
    "Voy a obtener todo de la carpeta de despliegue, copiarlo y pegarlo todo en el directorio de trabajo de la imagen de Docker (que es la carpeta `app`).\n",
    "\n",
    "Es una buena práctica dejar el dockerfile en la misma carpeta donde está el código de la aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "COPY . .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los servicios que necesitamos que sigan funcionando usamos el comando `CMD`\n",
    "\n",
    "`CMD` → Para iniciar el servicio. Por ejemplo, una aplicación que debería recibir solicitudes todo el tiempo. Este es el último comando en el dockerfile.\n",
    "\n",
    "Ejecutaremos la aplicación con `python3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CMD [\"python3\",\"main.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, al final, el archivo Docker se ve así:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "EXPOSE 80\n",
    "\n",
    "COPY requirements.txt .\n",
    "\n",
    "RUN [\"pip\", \"install\", \"-r\",\"./requirements.txt\"]\n",
    "\n",
    "COPY . .\n",
    "\n",
    "CMD [\"python3\",\"main.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el molde de la imagen de docker que vamos a crear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambios para hacer en nuestro archivo del backend, main.py\n",
    "**1. Incluir CORSMiddleware**\n",
    "\n",
    "CORS un mecanismo para controlar quién puede acceder a nuestra API, quién puede realizar solicitudes y obtener respuestas. Tenemos que incluir esto en nuestro archivo `main.py`. Puedes consultar la documentación de fastAPI [aquí](https://fastapi.tiangolo.com/tutorial/cors/).\n",
    "\n",
    "Un middleware es una función que se aplica a cada solicitud que llega a nuestra aplicación y también a cada respuesta. Lo cual es muy útil, por ejemplo en este caso, esta función modifica el encabezado de las solicitudes a la API para incluir información sobre qué dominios están permitidos.\n",
    "\n",
    "En este caso, habilitaremos las solicitudes desde todas partes, agregando este fragmento de código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, en este caso incluir esto no es absolutamente necesario ya que esta implementación será local. Para desarrollo es útil, pero es inseguro permitir solicitudes de todas partes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cambiar el puerto Localhost**\n",
    "\n",
    "El puerto 3000 es localhost y deberíamos cambiarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    uvicorn.run(\"main:app\", port=3000, reload=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualmente la aplicación intentará ejecutarse en enlocalhost en el `puerto 3000`. Eso no va a funcionar. Porque el host local del contenedor de la ventana acoplable no estará expuesto al host que ejecuta el contenedor. Incluso si lo fuera, no sería apropiado porque el puerto que exponen nuestras imágenes de la ventana acoplable es el `puerto 80`.\n",
    "\n",
    "Tenemos que especificar un nuevo host. Por defecto es localhost. PERO para que esto sea accesible desde el exterior, incluida la máquina host que ejecuta el contenedor de Docker, el host debe ser el `“0.0.0.0”`\n",
    "\n",
    "Cuando ejecutamos la aplicación debemos asegurarnos de que se esté ejecutando en la `IP: “0.0.0.0\"` y el `Puerto: “80”`.\n",
    "\n",
    "Así debe quedar el main del archivo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    # For local development:\n",
    "    # uvicorn.run(\"main:app\", port=3000, reload=True)\n",
    "\n",
    "    # for docker deployment:\n",
    "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=80)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #4**\n",
    "\n",
    "Tener el Dockerfile armado y el archivo main.py modificado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora sí podemos crear la Imagen de Docker!\n",
    "**1. Crear la Imagen de Docker.**\n",
    "\n",
    "Abre la terminal, dirigete a la carpeta de `despliegue` y corre el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker build -t taxi-app .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `.` representa la carpeta donde se encuentra el dockerfile.\n",
    "\n",
    "Nota: el proceso de crear la imagen de docker puede tardar unos cuantos minutos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Dirigete al Docker Desktop**\n",
    "\n",
    "Hemos creado una nueva imagen de Docker a partir de nuestro dockerfile y podemos verla en el Docker Desktop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image15.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos usar esa imagen para crear el contenedor de Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Crear el Contenedor de Docker**\n",
    "\n",
    "Estamos ejecutando una imagen para crear un contenedor.\n",
    "\n",
    "La ejecución de Docker es diferente del inicio de Docker.\n",
    "\n",
    "- `docker run`: crea nuevos contenedores a partir de imágenes.\n",
    "- `docker start`: reinicia todos los contenedores que ya se han creado.\n",
    "\n",
    "Ahora corre en la terminal el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker run -p 3000:80 taxi-app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos especificar un `\"port binding\"`, o un enlace de puertos.\n",
    "\n",
    "`3000` → es el puerto en el host.\n",
    "\n",
    "`80` → es el puerto en el contenedor. Este debería ser un puerto que exponga la imagen. Si especificamos algo diferente de `80`, la aplicación no podrá comunicarse con el host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Ahora dirigete a [http://localhost:3000/docs](http://localhost:3000/docs)**\n",
    "\n",
    "¡Podemos observar nuestra app con éxito!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image16.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista nuestra aplicación se ve igual a cómo se veía antes, pero hemos hecho algo independiente del entorno y del sistema operativo. Funciona para mi mac y funcionará en cualquier lugar.\n",
    "\n",
    "Cuando ejecutamos: se está ejecutando localmente pero desde su propio sistema operativo, desde un contenedor Docker que es algo similar a una VM que se ejecuta dentro de nuestra máquina. Este docker va a funcionar desde cualquier sistema operativo y cualquier entorno siempre que tengamos la aplicación Docker Desktop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #5**\n",
    "\n",
    "Try out! Ensaya el segundo método POST con features reales:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"vendor_id\": 2,\n",
    "  \"pickup_datetime\": \"2016-03-14 17:24:55\",\n",
    "  \"passenger_count\": 1,\n",
    "  \"pickup_longitude\": -73.9821548462,\n",
    "  \"pickup_latitude\": 40.7679367065,\n",
    "  \"dropoff_longitude\": -73.964630127,\n",
    "  \"dropoff_latitude\": 40.7656021118,\n",
    "  \"pickup_borough\": \"Manhattan\",\n",
    "  \"dropoff_borough\": \"Manhattan\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
