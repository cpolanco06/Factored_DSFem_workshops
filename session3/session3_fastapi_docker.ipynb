{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creaci√≥n de APIs con FastAPI\n",
    "El objetivo de esta secci√≥n es crear una API para consumir uno de los modelos que se generaron en el workshop anterior \"scikit-learn y MLFlow\". De igual forma, se emplear√° el pipeline de preprocesamiento de datos que se cre√≥ en el workshop anterior  \"Pipelines en scikit-learn\". \n",
    "\n",
    "Antes de arrancar, aseguremosnos de tener las siguientes dependencias en nuestro entorno de desarrollo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dill==0.3.3\n",
    "scikit-learn==0.24.1\n",
    "python-multipart==0.0.5\n",
    "numpy==1.21.0\n",
    "pandas==1.2.5\n",
    "matplotlib==3.4.2\n",
    "mlflow==1.20.2\n",
    "seaborn==0.11.1\n",
    "fastapi==0.68.1\n",
    "uvicorn==0.15.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "dill.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn\n",
    "seaborn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.68.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastapi\n",
    "fastapi.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uvicorn\n",
    "uvicorn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multipart\n",
    "multipart.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elecci√≥n del modelo que se va a desplegar\n",
    "Antes de iniciar el c√≥digo de nuestra primer API usando FastAPI, recordemos el final del workshop anterior, donde exportamos el pipeline de preprocesamiento de los datos y el modelo en objetos \".dill\".\n",
    "\n",
    "Creamos un contexto usando `open()` y usamos la funci√≥n `dill.dump()` para guardar nuestro flujo de preprocesamiento en disco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import dill\n",
    "dill.settings['recurse'] = True\n",
    "dill.dump(full_pipeline, f, protocol=dill.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('./preprocesser.pkl', 'wb') as f:\n",
    "    dill.dump(full_pipeline, f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un contexto usando `open()` y usamos la funci√≥n `dill.dump()` para guardar nuestro modelo en disco. El modelo que usaremos es la Regresi√≥n Lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with open('./lr_model.pkl', 'wb') as f:\n",
    "    dill.dump(model,f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, tambi√©n necesitamos un archivo llamado \"requirements.txt\".\n",
    "\n",
    "El archivo \"requirements.txt\" tiene los requerimientos para la API, que se pueden observar a continuaci√≥n:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dill==0.3.3\n",
    "scikit-learn==0.24.1\n",
    "python-multipart==0.0.5\n",
    "numpy==1.21.0\n",
    "pandas==1.2.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a elegir un lugar en nuestro directorio para poner todos los archivos relacionados al despliegue del modelo. A √©sta carpeta la podemos nombrar \"despliegue\" y los primeros archivos que almacenaremos ac√° ser√°n el pipeline de procesamiento \"preprocesser.pkl\", el script \"transformes.py\" el cual es usado por el preprocesador, el modelo Regresi√≥n Linear 'lr_model.dill' y el archivo \"requirements.txt\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "despliegue\n",
    "‚îú‚îÄ‚îÄ preprocesser.pkl\n",
    "‚îú‚îÄ‚îÄ lr_model.pkl\n",
    "‚îú‚îÄ‚îÄ transformers.py\n",
    "‚îî‚îÄ‚îÄ requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar dependencias, Preprocesador y Modelo\n",
    "1. Importaremos las dependencias en la ruta de despliegue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r /despliegue/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Vamos a crear un script en nuestra carpeta de despliegue llamado `main.py`. Y vamos a importar las  dependencias necesariar para usar FastAPI, el preprocesador y el modelo. Tambi√©n vamos a crear nuestra API, la cual tendr√° el nombre de \"Taxi Trips Duration Predictor\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "from fastapi import FastAPI, File\n",
    "from fastapi.responses import JSONResponse\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from transformers import TransformerFechas, TransformerDistancia, TransformerVelocidad\n",
    "\n",
    "app = FastAPI(title=\"Taxi Trips Duration Predictor\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Ahora vamos a importar el modelo y el preprocesador que creamos y exportamos en la sesi√≥n anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# import the preprocessor\n",
    "with open(\"preprocesser.pkl\", \"rb\") as f:\n",
    "    preprocessor = dill.load(f)\n",
    "# import the model\n",
    "with open(\"lr_model.pkl\", \"rb\") as f:\n",
    "    model = dill.load(f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solicitudes y Respuestas\n",
    "Las API funcionan mediante ‚Äúsolicitudes‚Äù y ‚Äúrespuestas‚Äù. Cuando una API solicita informaci√≥n de una aplicaci√≥n web o un servidor web, recibir√° una respuesta. \n",
    "\n",
    "Nuestra API tendr√° la funcionalidad de recibir \"solicitudes\" con los datos de los features que requiere el modelo, luego la l√≥gica del negocio procesar√° los datos y finalmente la API devolver√° una \"respuesta\" con la predicci√≥n del modelo. En este caso, la l√≥gica del negocio consiste en el pipeline de preprocesamiento y el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puntos finales o \"Endpoints\" \n",
    "El lugar al que las API env√≠an solicitudes y donde reside el recurso se denomina \"endpoint\".\n",
    "\n",
    "Cuando una API interact√∫a con otro sistema, los puntos de contacto de esta comunicaci√≥n se consideran puntos finales. Para las API, un punto final puede incluir una URL de un servidor o servicio. Cada punto final es la ubicaci√≥n desde la que las API pueden acceder a los recursos que necesitan para llevar a cabo su funci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer Endpoint: Get Endpoint\n",
    "Las solicitudes GET son los m√©todos m√°s comunes y m√°s utilizados en API y sitios web. El m√©todo GET se utiliza para recuperar datos de un servidor en el recurso especificado. Por ejemplo, supongamos que tiene una API con un punto final /users. Hacer una solicitud GET a ese punto final deber√≠a devolver una lista de todos los usuarios disponibles.\n",
    "\n",
    "`GET` es un m√©todo que puede recibir par√°metros a trav√©s de par√°metros \"path\" o par√°metros \"query\":\n",
    "\n",
    "- `Path Parameters`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.get(\"/{}\", response_class=JSONResponse)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes revisar la documentaci√≥n de `Path Parameters` en FastAPI [ac√°](https://fastapi.tiangolo.com/tutorial/path-params/).\n",
    "\n",
    "- `Query Parameters`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.get(\"/\", response_class=JSONResponse)\n",
    "def get_funct(\n",
    "    vendor_id: int,\n",
    "    pickup_datetime: str,\n",
    "    passenger_count: int,\n",
    "    pickup_longitude: float,\n",
    "    pickup_latitude: float,\n",
    "    dropoff_longitude: float,\n",
    "    dropoff_latitude: float,\n",
    "    pickup_borough: str,\n",
    "    dropoff_borough: str,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los `Query Parameters`, los par√°metros se definen al interior de la funci√≥n `get_func()`.\n",
    "\n",
    "Puedes revisar la documentaci√≥n de `Query Parameters` en FastAPI [ac√°](https://fastapi.tiangolo.com/tutorial/query-params/).\n",
    "\n",
    "En el presente ejemplo nuestro m√©todo `GET` recibir√° los par√°metros con la convenci√≥n de query parameters y retornar√° la respuesta de la predicci√≥n en un JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "from fastapi import FastAPI, File\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "from transformers import TransformerFechas, TransformerDistancia, TransformerVelocidad\n",
    "\n",
    "app = FastAPI(title=\"Taxi Trips Duration Predictor\")\n",
    "\n",
    "# import the preprocessor\n",
    "with open(\"preprocesser.pkl\", \"rb\") as f:\n",
    "    preprocessor = dill.load(f)\n",
    "# import the model\n",
    "with open(\"lr_model.pkl\", \"rb\") as f:\n",
    "    model = dill.load(f)\n",
    "\n",
    "\n",
    "@app.get(\"/\", response_class=JSONResponse)\n",
    "def get_funct(\n",
    "    vendor_id: int,\n",
    "    pickup_datetime: str,\n",
    "    passenger_count: int,\n",
    "    pickup_longitude: float,\n",
    "    pickup_latitude: float,\n",
    "    dropoff_longitude: float,\n",
    "    dropoff_latitude: float,\n",
    "    pickup_borough: str,\n",
    "    dropoff_borough: str,\n",
    "):\n",
    "    \"\"\"Serves predictions given query parameters specifying the taxi trip's\n",
    "    features from a single example.\n",
    "\n",
    "    Args:\n",
    "        vendor_id (int): a code indicating the provider associated with the trip record\n",
    "        pickup_datetime (str): date and time when the meter was engaged\n",
    "        passenger_count (float): the number of passengers in the vehicle\n",
    "        (driver entered value)\n",
    "        pickup_longitude (float): the longitude where the meter was engaged\n",
    "        pickup_latitude (float): the latitude where the meter was engaged\n",
    "        dropoff_longitude (float): the longitude where the meter was disengaged\n",
    "        dropoff_latitude (float): the latitude where the meter was disengaged\n",
    "        pickup_borough (str): the borough where the meter was engaged\n",
    "        dropoff_borough (str): the borough where the meter was disengaged\n",
    "\n",
    "    Returns:\n",
    "        [JSON]: model prediction for the single example given\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                vendor_id,\n",
    "                pickup_datetime,\n",
    "                passenger_count,\n",
    "                pickup_longitude,\n",
    "                pickup_latitude,\n",
    "                dropoff_longitude,\n",
    "                dropoff_latitude,\n",
    "                pickup_borough,\n",
    "                dropoff_borough,\n",
    "            ]\n",
    "        ],\n",
    "        columns=[\n",
    "            \"vendor_id\",\n",
    "            \"pickup_datetime\",\n",
    "            \"passenger_count\",\n",
    "            \"pickup_longitude\",\n",
    "            \"pickup_latitude\",\n",
    "            \"dropoff_longitude\",\n",
    "            \"dropoff_latitude\",\n",
    "            \"pickup_borough\",\n",
    "            \"dropoff_borough\",\n",
    "        ],\n",
    "    )\n",
    "    prediction = model.predict(preprocessor.transform(df))\n",
    "    return {\n",
    "        \"features\": {\n",
    "            \"vendor_id\": vendor_id,\n",
    "            \"pickup_datetime\": pickup_datetime,\n",
    "            \"passenger_count\": passenger_count,\n",
    "            \"pickup_longitude\": pickup_longitude,\n",
    "            \"pickup_latitude\": pickup_latitude,\n",
    "            \"dropoff_longitude\": dropoff_longitude,\n",
    "            \"dropoff_latitude\": dropoff_latitude,\n",
    "            \"pickup_borough\": pickup_borough,\n",
    "            \"dropoff_borough\": dropoff_borough,\n",
    "        },\n",
    "        \"prediction\": list(prediction)[0],\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    # For local development:\n",
    "    uvicorn.run(\"main:app\", port=3000, reload=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos el main de nuestra API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    # For local development:\n",
    "    uvicorn.run(\"main:app\", port=3000, reload=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reload=True` permite que cada vez que se guarde el archivo main.py, la API se actualice autom√°ticamente, sin necesidad de cerrar la API y volverla a reiniciar cada vez que se haga un cambio. Esta es una funcionalidad muy √∫til durante la etapa de desarrollo de la API, no es recomendable tenerla en la etapa de despligue. \n",
    "\n",
    "As√≠ es como se debe ver ahora la estructura de la carpeta `despliegue`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "despliegue\n",
    "‚îú‚îÄ‚îÄ preprocesser.pkl\n",
    "‚îú‚îÄ‚îÄ lr_model.pkl\n",
    "‚îú‚îÄ‚îÄ transformers.py\n",
    "‚îú‚îÄ‚îÄ main.py\n",
    "‚îî‚îÄ‚îÄ requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n debemos ir a la terminal, ubicarnos en la carpeta \"despliegue\" y correr el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python main.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la terminal obtendremos una salida as√≠:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬°A continuaci√≥n viene la mejor parte! ¬°Vamos a probar nuestra API!\n",
    "\n",
    "As√≠ que ahora ve a tu buscador preferido, puede ser Chrome, Safari, ojal√° no Internet Explorer üòÅ  si quieres acabar este workpshop hoy ü§≠  \n",
    "\n",
    "Una vez en el buscador, coloca esta direcci√≥n [`http://127.0.0.1:3000`](http://127.0.0.1:3000)\n",
    "\n",
    "Si nos quedamos en esta direcci√≥n podr√≠amos pasar los features del modelo editando la URL directamente, pero esto ser√≠a engorroso. Afortunadamente FastAPI tiene por default un Front que podemos usar con cualquiera de nuestras APIs. As√≠ que s√≥lo debemos hacer un cambio en la URL:\n",
    "\n",
    "[`http://127.0.0.1:3000/docs`](http://127.0.0.1:3000/docs)\n",
    "\n",
    "Ahora deber√≠as ver algo as√≠ en el buscador:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image4.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, presionando \"Try it out\" puedes rellenar para cada feature su valor correspondiente, de esta forma el modelo recibe los datos que va a preprocesar y luego el modelo podr√° generar su predicci√≥n y enviarla como respuesta!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #1**\n",
    "\n",
    "Try out! Ensayar el m√©todo GET con features reales:\n",
    "- vendor_id: 2\n",
    "- pickup_datetime: 2016-03-14 17:24:55\n",
    "- passenger_count: 1\n",
    "- pickup_longitude: -73.9821548462\n",
    "- pickup_latitude: 40.7679367065\n",
    "- dropoff_longitude: -73.964630127\n",
    "- dropoff_latitude: 40.7656021118\n",
    "- pickup_borough: Manhattan\n",
    "- dropoff_borough: Manhattan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final debes obtener el codigo de respuesta √©xitosa, es decir 200, y la predicci√≥n del modelo. Se debe ver m√°s o menos as√≠:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image6.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Endpoint: Post Endpoint\n",
    "En los servicios web, las solicitudes POST se utilizan para enviar datos al servidor API para crear o actualizar un recurso. Los datos enviados al servidor se almacenan en el cuerpo de la solicitud HTTP.\n",
    "\n",
    "El ejemplo m√°s simple es un formulario de contacto en un sitio web. Cuando completas las entradas en un formulario y presionas Enviar, esos datos se colocan en el cuerpo de respuesta de la solicitud y se env√≠an al servidor. Puede ser JSON, XML o par√°metros de consulta (query parameters).\n",
    "\n",
    "En este caso, nos gustar√≠a que nuestro m√©todo POST reciba un JSON y retorne un JSON.\n",
    "\n",
    "`BaseModel`  de [pydantic](https://pydantic-docs.helpmanual.io/) es una clase de la cu√°l vamos a heredar para crear las especificaciones del JSON que va a ingresar en nuestro Endpoint. Por eso la debemos agregar a nuestras dependencias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "from fastapi import FastAPI, File\n",
    "from fastapi.responses import JSONResponse, StreamingResponse\n",
    "from pydantic import BaseModel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear la clase TaxiTrip, que hereda de BaseModel. TaxiTrip va a ser un objeto con 9 par√°metros que describen un viaje en taxi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class TaxiTrip(BaseModel):\n",
    "    vendor_id: int\n",
    "    pickup_datetime: str\n",
    "    passenger_count: float\n",
    "    pickup_longitude: float\n",
    "    pickup_latitude: float\n",
    "    dropoff_longitude: float\n",
    "    dropoff_latitude: float\n",
    "    pickup_borough: str\n",
    "    dropoff_borough: str\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, en nuestro `POST` endpoint vamos a definir que el par√°metro que entra es un taxitrip de tipo TaxiTrip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.post(\"/json\", response_class=JSONResponse)\n",
    "def post_json(taxitrip: TaxiTrip):\n",
    "    \"\"\"Serves predictions given a request body specifying the taxis trip's features\n",
    "    from a single example.\n",
    "\n",
    "    Args:\n",
    "        taxitrip (TaxiTrip): request body of type `TaxiTrip` with the\n",
    "        attributes: vendor_id, pickup_datetime, passenger_count, pickup_longitude,\n",
    "        pickup_latitude, dropoff_longitude, dropoff_latitude, pickup_borough and\n",
    "        dropoff_borough\n",
    "\n",
    "    Returns:\n",
    "        [JSON]: model prediction for the single example given\n",
    "    \"\"\"\n",
    "    vendor_id = taxitrip.vendor_id\n",
    "    pickup_datetime = taxitrip.pickup_datetime\n",
    "    passenger_count = taxitrip.passenger_count\n",
    "    pickup_longitude = taxitrip.pickup_longitude\n",
    "    pickup_latitude = taxitrip.pickup_latitude\n",
    "    dropoff_longitude = taxitrip.dropoff_longitude\n",
    "    dropoff_latitude = taxitrip.dropoff_latitude\n",
    "    pickup_borough = taxitrip.pickup_borough\n",
    "    dropoff_borough = taxitrip.dropoff_borough\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                vendor_id,\n",
    "                pickup_datetime,\n",
    "                passenger_count,\n",
    "                pickup_longitude,\n",
    "                pickup_latitude,\n",
    "                dropoff_longitude,\n",
    "                dropoff_latitude,\n",
    "                pickup_borough,\n",
    "                dropoff_borough,\n",
    "            ]\n",
    "        ],\n",
    "        columns=[\n",
    "            \"vendor_id\",\n",
    "            \"pickup_datetime\",\n",
    "            \"passenger_count\",\n",
    "            \"pickup_longitude\",\n",
    "            \"pickup_latitude\",\n",
    "            \"dropoff_longitude\",\n",
    "            \"dropoff_latitude\",\n",
    "            \"pickup_borough\",\n",
    "            \"dropoff_borough\",\n",
    "        ],\n",
    "    )\n",
    "    prediction = model.predict(preprocessor.transform(df))\n",
    "    return {\n",
    "        \"features\": {\n",
    "            \"vendor_id\": vendor_id,\n",
    "            \"pickup_datetime\": pickup_datetime,\n",
    "            \"passenger_count\": passenger_count,\n",
    "            \"pickup_longitude\": pickup_longitude,\n",
    "            \"pickup_latitude\": pickup_latitude,\n",
    "            \"dropoff_longitude\": dropoff_longitude,\n",
    "            \"dropoff_latitude\": dropoff_latitude,\n",
    "            \"pickup_borough\": pickup_borough,\n",
    "            \"dropoff_borough\": dropoff_borough,\n",
    "        },\n",
    "        \"prediction\": list(prediction)[0],\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, guardamos los cambios en el archivo `main.py` y recargamos la p√°gina:\n",
    "\n",
    "[`http://127.0.0.1:3000/docs`](http://127.0.0.1:3000/docs)\n",
    "\n",
    "Como podremos observar, ya nuestro `POST` Endpoint est√° listo para usar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image7.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #2**\n",
    "\n",
    "Try out! Ensayar el m√©todo POST con features reales:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"vendor_id\": 2,\n",
    "  \"pickup_datetime\": \"2016-03-14 17:24:55\",\n",
    "  \"passenger_count\": 1,\n",
    "  \"pickup_longitude\": -73.9821548462,\n",
    "  \"pickup_latitude\": 40.7679367065,\n",
    "  \"dropoff_longitude\": -73.964630127,\n",
    "  \"dropoff_latitude\": 40.7656021118,\n",
    "  \"pickup_borough\": \"Manhattan\",\n",
    "  \"dropoff_borough\": \"Manhattan\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final debes obtener el codigo de respuesta √©xitosa, es decir 200 y la predicci√≥n del modelo. Se debe ver m√°s o menos as√≠:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image8.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tercer Endpoint: POST Endpoint\n",
    "Este √∫ltimo Endpoint ser√° diferente al anterior ya que recibir√° como entrada un archivo y devolver√° un archivo a su vez. Por esto, debemos importar otro tipo de respuesta de FastAPI en nuestras dependencias, el `StreamingResponse`.\n",
    "\n",
    "Por otro lado, nuestro m√©todo `POST` va a recibir un par√°metro de tipo `File`, as√≠ que tambi√©n lo debemos importar de la librer√≠a `fastapi`.\n",
    "\n",
    "Adem√°s, debemos traer la clase `BytesIO` de la librer√≠a `io`, la cual toma un objeto bytes que est√° en memoria en python e imita el comportamiento de un archivo, de lo que Python considera un objeto tipo archivo, el cual tiene m√©todos de \"read\" y \"write\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "from fastapi import FastAPI, File\n",
    "from fastapi.responses import JSONResponse, StreamingResponse\n",
    "from pydantic import BaseModel\n",
    "from io import BytesIO\n",
    "\n",
    "from transformers import TransformerFechas, TransformerDistancia, TransformerVelocidad\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StreamingResponse` es muy √∫til ya que no guarda los archivos en disco sino que en el Browser recibe el archivo. De esta forma ahorramos espacio en el disco, evitamos las operaciones en disco y las hacemos en memoria, lo cual es mucho m√°s r√°pido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.post(\"/file\", response_class=StreamingResponse)\n",
    "def post_file(file: bytes = File(...)):\n",
    "    \"\"\"Serves predictions given a CSV file with no header and seven columns\n",
    "    specifying each taxi trip's features in the order vendor_id, pickup_datetime,\n",
    "    passenger_count, pickup_longitude,pickup_latitude, dropoff_longitude and\n",
    "    dropoff_latitude, pickup_borough and dropoff_borough\n",
    "\n",
    "    Args:\n",
    "        file (bytes, optional): bytes from a CSV file as described above.\n",
    "         Defaults to File(...), but to receive a file is required.\n",
    "\n",
    "    Returns:\n",
    "        [StreamingResponse]: Returns a streaming response with a new CSV file that contains\n",
    "        a column with the predictions.\n",
    "    \"\"\"\n",
    "    # Decode the bytes as text and split the lines:\n",
    "    input_lines = file.decode().splitlines()\n",
    "\n",
    "    # Split each line as a list of the three features:\n",
    "    X = [p.split(\",\") for p in input_lines]\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        vendor_id = int(x[0])\n",
    "        pickup_datetime = str(x[1])\n",
    "        passenger_count = float(x[2])\n",
    "        pickup_longitude = float(x[3])\n",
    "        pickup_latitude = float(x[4])\n",
    "        dropoff_longitude = float(x[5])\n",
    "        dropoff_latitude = float(x[6])\n",
    "        pickup_borough = str(x[7])\n",
    "        dropoff_borough = str(x[8])\n",
    "        df = pd.DataFrame(\n",
    "            [\n",
    "                [\n",
    "                    vendor_id,\n",
    "                    pickup_datetime,\n",
    "                    passenger_count,\n",
    "                    pickup_longitude,\n",
    "                    pickup_latitude,\n",
    "                    dropoff_longitude,\n",
    "                    dropoff_latitude,\n",
    "                    pickup_borough,\n",
    "                    dropoff_borough,\n",
    "                ]\n",
    "            ],\n",
    "            columns=[\n",
    "                \"vendor_id\",\n",
    "                \"pickup_datetime\",\n",
    "                \"passenger_count\",\n",
    "                \"pickup_longitude\",\n",
    "                \"pickup_latitude\",\n",
    "                \"dropoff_longitude\",\n",
    "                \"dropoff_latitude\",\n",
    "                \"pickup_borough\",\n",
    "                \"dropoff_borough\",\n",
    "            ],\n",
    "        )\n",
    "        # Get predictions for each taxi trip:\n",
    "        prediction = model.predict(preprocessor.transform(df))\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # Append the prediction to each input line:\n",
    "    output = [line + \",\" + str(pred[0]) for line, pred in zip(input_lines, predictions)]\n",
    "    # Join the output as a single string:\n",
    "    output = \"\\n\".join(output)\n",
    "    # Encode output as bytes:\n",
    "    output = output.encode()\n",
    "\n",
    "    # The kind is text, the extension is csv\n",
    "    return StreamingResponse(\n",
    "        BytesIO(output),\n",
    "        media_type=\"text/csv\",\n",
    "        headers={\"Content-Disposition\": 'attachment;filename=\"prediction.csv\"'},\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, guardamos los cambios en el archivo main.py y recargamos la p√°gina:\n",
    "\n",
    "[`http://127.0.0.1:3000/docs`](http://127.0.0.1:3000/docs)\n",
    "\n",
    "Como podremos observar, ya nuestro tercer Endpoint (POST) est√° listo para usar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tercer endpoint recibe un archivo .CSV con diferentes ejemplos, te reto a generar las predicciones de los ejemplos en el siguiente archivo:\n",
    "\n",
    "`example.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #3**\n",
    "\n",
    "Try out! Ensayar el m√©todo POST con features reales del archivo CSV previo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final debes obtener el codigo de respuesta √©xitosa, es decir 200 y la predicci√≥n del modelo. Se debe ver m√°s o menos as√≠:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, desde el buscador podemos descargar un archivo que contendr√° los features de cada ejemplo y sus respectivas predicciones. Ese archivo se llamar√° \"prediction.csv\" y su contenido se debe ver as√≠:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image11.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar la predicci√≥n fue la misma para ambos ejemplos, esto nos indica que la Regresi√≥n Lineal no es un modelo muy robusto. Para este workshop se decidi√≥ usar la Regresi√≥n Lineal por simplicidad y por ser un modelo liviano, pero lo recomendable es siempre elegir el mejor modelo que se haya encontrada en la etapa de experimentaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Despliegue de Software con Docker\n",
    "En esta secci√≥n vamos desplegar nuestra API usando Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es un Contenedor de Docker?\n",
    "Es una herramienta que nos permite aislar el entorno de cualquier software que queramos implementar.\n",
    "\n",
    "Si desarrollo una pieza de software en mi entorno, con ciertas dependencias y versiones de las bibliotecas que uso en un sistema operativo espec√≠fico, entonces, lo que hice en mi PC, podr√≠a no funcionar en otro PC. \n",
    "\n",
    "El contenedor de Docker es como un mini computador, est√° asociado al concepto de m√°quinas virtuales. Sin embargo, las m√°quinas virtuales asignan una gran cantidad de recursos, incluso si la aplicaci√≥n no se est√° utilizando. \n",
    "\n",
    "Cuando el contenedor de Docker no usa recursos, no bloquea el host para usarlos, por lo que es m√°s eficiente que las m√°quinas virtuales.\n",
    "\n",
    "El contenedor de Docker tiene un sistema operativo espec√≠fico, normalmente Linux. La aplicaci√≥n se ejecuta all√≠, de tal manera que no importa qui√©n la ejecute o en qu√© computadora, el sistema operativo y las bibliotecas operativo son los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es una Imagen de Docker?\n",
    "Es como un molde de donde se crean los contenedores.\n",
    "\n",
    "Un contenedor es una instanciaci√≥n espec√≠fica de la imagen de Docker, que puede ejecutarse en cualquier host que tenga la aplicaci√≥n de escritorio de Docker (Docker desktop).\n",
    "\n",
    "Para seleccionar una imagen de Docker, debemos partir de una imagen que ya tenga algunas de nuestras dependencias. Por ejemplo, en este caso nos interesar√° una imagen que ya tenga python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øD√≥nde encontramos las im√°genes de Docker?\n",
    "Dockerhub es el repositorio oficial de im√°genes de Docker\n",
    "\n",
    "[Docker Hub Container Image Library | App Containerization](https://hub.docker.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src='../imgs/image12.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora busquemos una imagen que ya contenga FastAPI usando las palabras clave ‚Äútiangolo fastapi‚Äù:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image13.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera imagen que podemos ver, `tiangolo/uvicorn-gunicorn-fastapi` es lo m√°s cercano a una ‚Äúimagen oficial de Docker de fastapi‚Äù que encontraremos, ya que fue desarrollada por tiangolo, el creador de fastapi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es un Dockerfile?\n",
    "Una imagen de Docker es un molde para crear un contenedor de Docker, y ¬øc√≥mo creamos ese molde? Con un Dockerfile.\n",
    "\n",
    "Un Dockerfile es la receta para crear el molde.\n",
    "\n",
    "Un Dockerfile es un archivo con un conjunto de pasos que le dicen a Docker c√≥mo crear esa imagen.\n",
    "\n",
    "Vamos a crear un archivo llamado Dockerfile, en la misma carpeta donde tenemos nuestra aplicaci√≥n y luego vamos a escribir algunos comandos en √©l.\n",
    "\n",
    "El directorio deber√≠a verse as√≠ ahora mismo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "despliegue\n",
    "‚îú‚îÄ‚îÄ preprocesser.pkl\n",
    "‚îú‚îÄ‚îÄ lr_model.pkl\n",
    "‚îú‚îÄ‚îÄ transformers.py\n",
    "‚îú‚îÄ‚îÄ main.py\n",
    "‚îú‚îÄ‚îÄ Dockerfile\n",
    "‚îî‚îÄ‚îÄ requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comandos del Dockerfile\n",
    "`FROM` ‚Üí aqu√≠ especificamos en qu√© imagen nos basamos para crear nuestra imagen propia.\n",
    "\n",
    "Ya seleccionamos la imagen base `tiangolo/uvicorn-gunicorn-fastapi` Pero tambi√©n tenemos que seleccionar una versi√≥n o una etiqueta en la secci√≥n `Tags`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image14.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y vamos a seleccionar la etiqueta `python3.9-slim`, que es una versi√≥n liviana de python.\n",
    "\n",
    "Entonces, el comando `FROM` se ver√° as√≠:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9-slim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`WORKDIR` ‚Üí Para especificar nuestro directorio de trabajo. Ya est√° especificado en la imagen de Docker pero es bueno saber en que directorio de trabajo estamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "WORKDIR /app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EXPOSE` ‚Üí El puerto que vamos a exponer. Ya est√° especificado en la imagen de Docker pero es bueno saber qu√© puerto est√° expuesto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "EXPOSE 80\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el comando `COPY` para traer el archivo `requirements.txt` ubicado en la carpeta donde se encuentra el `Dockerfile`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "COPY requirements.txt .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Run` ‚Üí Queremos incluir algunas dependencias\n",
    "\n",
    "`-r` ‚Üí  ejecutar `pip -r`  permite recibir una ruta con una lista de dependencias que se requieran instalar. Es muy √∫til instalarlos todos a la vez.\n",
    "\n",
    "No se recomienda tener varios comandos RUN en el dockerfile, es mejor tener solo un comando RUN.\n",
    "\n",
    "`RUN` se utiliza para instalar dependencias normalmente. Para ejecutar cualquier cosa que necesitemos poner en nuestra imagen de Docker. Lo ejecutamos y termina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "RUN [\"pip\", \"install\", \"-r\",\"./requirements.txt\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`COPY` ‚Üí Necesitamos copiar cosas de nuestro host (de nuestra m√°quina) a la imagen de Docker. Se van a copiar en el contenedor de Docker cuando iniciemos la imagen para crear el contenedor. Esto se puede hacer con paths relativos.\n",
    "\n",
    "Lo que sea que est√© dentro de mi carpeta de `despliegue` es lo que quiero que est√© en mi directorio de trabajo en el contenedor de Docker o la imagen de Docker.\n",
    "\n",
    "`COPY .` ‚Üí El 1er punto representa la carpeta donde est√° el Dockerfile. Entonces, en este caso, se refiere a la carpeta despliegue.\n",
    "\n",
    "`COPY . .` ‚Üí El 2ndo punto se refiere al directorio de trabajo dentro de la imagen de Docker.\n",
    "\n",
    "Voy a obtener todo de la carpeta de despliegue, copiarlo y pegarlo todo en el directorio de trabajo de la imagen de Docker (que es la carpeta `app`).\n",
    "\n",
    "Es una buena pr√°ctica dejar el dockerfile en la misma carpeta donde est√° el c√≥digo de la aplicaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "COPY . .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los servicios que necesitamos que sigan funcionando usamos el comando `CMD`\n",
    "\n",
    "`CMD` ‚Üí Para iniciar el servicio. Por ejemplo, una aplicaci√≥n que deber√≠a recibir solicitudes todo el tiempo. Este es el √∫ltimo comando en el dockerfile.\n",
    "\n",
    "Ejecutaremos la aplicaci√≥n con `python3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "CMD [\"python3\",\"main.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, al final, el archivo Docker se ve as√≠:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "EXPOSE 80\n",
    "\n",
    "COPY requirements.txt .\n",
    "\n",
    "RUN [\"pip\", \"install\", \"-r\",\"./requirements.txt\"]\n",
    "\n",
    "COPY . .\n",
    "\n",
    "CMD [\"python3\",\"main.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el molde de la imagen de docker que vamos a crear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambios para hacer en nuestro archivo del backend, main.py\n",
    "**1. Incluir CORSMiddleware**\n",
    "\n",
    "CORS un mecanismo para controlar qui√©n puede acceder a nuestra API, qui√©n puede realizar solicitudes y obtener respuestas. Tenemos que incluir esto en nuestro archivo `main.py`. Puedes consultar la documentaci√≥n de fastAPI [aqu√≠](https://fastapi.tiangolo.com/tutorial/cors/).\n",
    "\n",
    "Un middleware es una funci√≥n que se aplica a cada solicitud que llega a nuestra aplicaci√≥n y tambi√©n a cada respuesta. Lo cual es muy √∫til, por ejemplo en este caso, esta funci√≥n modifica el encabezado de las solicitudes a la API para incluir informaci√≥n sobre qu√© dominios est√°n permitidos.\n",
    "\n",
    "En este caso, habilitaremos las solicitudes desde todas partes, agregando este fragmento de c√≥digo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, en este caso incluir esto no es absolutamente necesario ya que esta implementaci√≥n ser√° local. Para desarrollo es √∫til, pero es inseguro permitir solicitudes de todas partes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cambiar el puerto Localhost**\n",
    "\n",
    "El puerto 3000 es localhost y deber√≠amos cambiarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    uvicorn.run(\"main:app\", port=3000, reload=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualmente la aplicaci√≥n intentar√° ejecutarse en enlocalhost en el `puerto 3000`. Eso no va a funcionar. Porque el host local del contenedor de la ventana acoplable no estar√° expuesto al host que ejecuta el contenedor. Incluso si lo fuera, no ser√≠a apropiado porque el puerto que exponen nuestras im√°genes de la ventana acoplable es el `puerto 80`.\n",
    "\n",
    "Tenemos que especificar un nuevo host. Por defecto es localhost. PERO para que esto sea accesible desde el exterior, incluida la m√°quina host que ejecuta el contenedor de Docker, el host debe ser el `‚Äú0.0.0.0‚Äù`\n",
    "\n",
    "Cuando ejecutamos la aplicaci√≥n debemos asegurarnos de que se est√© ejecutando en la `IP: ‚Äú0.0.0.0\"` y el `Puerto: ‚Äú80‚Äù`.\n",
    "\n",
    "As√≠ debe quedar el main del archivo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    # For local development:\n",
    "    # uvicorn.run(\"main:app\", port=3000, reload=True)\n",
    "\n",
    "    # for docker deployment:\n",
    "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=80)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #4**\n",
    "\n",
    "Tener el Dockerfile armado y el archivo main.py modificado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora s√≠ podemos crear la Imagen de Docker!\n",
    "**1. Crear la Imagen de Docker.**\n",
    "\n",
    "Abre la terminal, dirigete a la carpeta de `despliegue` y corre el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker build -t taxi-app .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `.` representa la carpeta donde se encuentra el dockerfile.\n",
    "\n",
    "Nota: el proceso de crear la imagen de docker puede tardar unos cuantos minutos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Dirigete al Docker Desktop**\n",
    "\n",
    "Hemos creado una nueva imagen de Docker a partir de nuestro dockerfile y podemos verla en el Docker Desktop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image15.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos usar esa imagen para crear el contenedor de Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Crear el Contenedor de Docker**\n",
    "\n",
    "Estamos ejecutando una imagen para crear un contenedor.\n",
    "\n",
    "La ejecuci√≥n de Docker es diferente del inicio de Docker.\n",
    "\n",
    "- `docker run`: crea nuevos contenedores a partir de im√°genes.\n",
    "- `docker start`: reinicia todos los contenedores que ya se han creado.\n",
    "\n",
    "Ahora corre en la terminal el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker run -p 3000:80 taxi-app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos especificar un `\"port binding\"`, o un enlace de puertos.\n",
    "\n",
    "`3000` ‚Üí es el puerto en el host.\n",
    "\n",
    "`80` ‚Üí es el puerto en el contenedor. Este deber√≠a ser un puerto que exponga la imagen. Si especificamos algo diferente de `80`, la aplicaci√≥n no podr√° comunicarse con el host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Ahora dirigete a [http://localhost:3000/docs](http://localhost:3000/docs)**\n",
    "\n",
    "¬°Podemos observar nuestra app con √©xito!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/image16.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista nuestra aplicaci√≥n se ve igual a c√≥mo se ve√≠a antes, pero hemos hecho algo independiente del entorno y del sistema operativo. Funciona para mi mac y funcionar√° en cualquier lugar.\n",
    "\n",
    "Cuando ejecutamos: se est√° ejecutando localmente pero desde su propio sistema operativo, desde un contenedor Docker que es algo similar a una VM que se ejecuta dentro de nuestra m√°quina. Este docker va a funcionar desde cualquier sistema operativo y cualquier entorno siempre que tengamos la aplicaci√≥n Docker Desktop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #5**\n",
    "\n",
    "Try out! Ensaya el segundo m√©todo POST con features reales:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"vendor_id\": 2,\n",
    "  \"pickup_datetime\": \"2016-03-14 17:24:55\",\n",
    "  \"passenger_count\": 1,\n",
    "  \"pickup_longitude\": -73.9821548462,\n",
    "  \"pickup_latitude\": 40.7679367065,\n",
    "  \"dropoff_longitude\": -73.964630127,\n",
    "  \"dropoff_latitude\": 40.7656021118,\n",
    "  \"pickup_borough\": \"Manhattan\",\n",
    "  \"dropoff_borough\": \"Manhattan\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
