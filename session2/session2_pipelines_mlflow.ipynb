{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines en scikit-learn\n",
    "El objetivo de esta sección es mostrar cómo se pueden desarrollar flujos de preprocesamiento en `sklearn`. Vamos a explorar las diferentes operaciones que se le pueden hacer a los diferentes tipos de variables y cómo agrupar todas las operaciones en un solo elemento de `sklearn` que tenga los métodos `.fit()` y `.transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1447855 entries, 0 to 1447854\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   id                  1447855 non-null  object \n",
      " 1   vendor_id           1447855 non-null  int64  \n",
      " 2   pickup_datetime     1447855 non-null  object \n",
      " 3   dropoff_datetime    1447855 non-null  object \n",
      " 4   passenger_count     1447855 non-null  int64  \n",
      " 5   pickup_longitude    1447855 non-null  float64\n",
      " 6   pickup_latitude     1447855 non-null  float64\n",
      " 7   dropoff_longitude   1447855 non-null  float64\n",
      " 8   dropoff_latitude    1447855 non-null  float64\n",
      " 9   store_and_fwd_flag  1447855 non-null  object \n",
      " 10  trip_duration       1447855 non-null  int64  \n",
      " 11  pickup_borough      1447855 non-null  object \n",
      " 12  dropoff_borough     1447855 non-null  object \n",
      "dtypes: float64(4), int64(3), object(6)\n",
      "memory usage: 154.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>pickup_borough</th>\n",
       "      <th>dropoff_borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>455</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-12 00:43:35</td>\n",
       "      <td>2016-06-12 00:54:38</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>N</td>\n",
       "      <td>663</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>2016-01-19 12:10:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>N</td>\n",
       "      <td>2124</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>2016-04-06 19:39:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>N</td>\n",
       "      <td>429</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>2016-03-26 13:38:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>N</td>\n",
       "      <td>435</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
       "1  id2377394          1  2016-06-12 00:43:35  2016-06-12 00:54:38   \n",
       "2  id3858529          2  2016-01-19 11:35:24  2016-01-19 12:10:48   \n",
       "3  id3504673          2  2016-04-06 19:32:31  2016-04-06 19:39:40   \n",
       "4  id2181028          2  2016-03-26 13:30:55  2016-03-26 13:38:10   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                1        -73.982155        40.767937         -73.964630   \n",
       "1                1        -73.980415        40.738564         -73.999481   \n",
       "2                1        -73.979027        40.763939         -74.005333   \n",
       "3                1        -74.010040        40.719971         -74.012268   \n",
       "4                1        -73.973053        40.793209         -73.972923   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag  trip_duration pickup_borough  \\\n",
       "0         40.765602                  N            455      Manhattan   \n",
       "1         40.731152                  N            663      Manhattan   \n",
       "2         40.710087                  N           2124      Manhattan   \n",
       "3         40.706718                  N            429       Brooklyn   \n",
       "4         40.782520                  N            435      Manhattan   \n",
       "\n",
       "  dropoff_borough  \n",
       "0       Manhattan  \n",
       "1        Brooklyn  \n",
       "2        Brooklyn  \n",
       "3        Brooklyn  \n",
       "4       Manhattan  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos dataset desde servidor de Factored\n",
    "#data = pd.read_csv(\"https://factored-workshops.s3.amazonaws.com/taxi-trip-duration.csv\")\n",
    "# Importamos dataset desde local\n",
    "data = pd.read_csv(\"../datasets/taxi-trip-duration.csv\")\n",
    "# Limitar rango de datos\n",
    "tiempo_minimo = 60 # 1 minuto\n",
    "tiempo_maximo = 36000 # 10 horas\n",
    "data = data[\n",
    "            (data[\"trip_duration\"] > tiempo_minimo) &\n",
    "            (data[\"trip_duration\"] < tiempo_maximo)\n",
    "]\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante siempre separar la variable dependiente—en este caso `trip_duration` del dataframe que vamos a usar para crear las variables independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"trip_duration\"]\n",
    "input_df = data.drop(\n",
    "    [\"id\", \"trip_duration\", \"dropoff_datetime\", \"store_and_fwd_flag\"],\n",
    "    axis=\"columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de los datos\n",
    "Un paso que siempre se debe hacer es dividir los datos disponibles entrenamiento, validación y test. En este caso vamos a dividir los datos disponibles en sets de entrenamiento y validación con la función `train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df, y_train, y_val = train_test_split(input_df, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "`scikit-learn` incluye una gran [lista](https://scikit-learn.org/stable/data_transforms.html) de transformers que nos permiten limpiar y transformar datos dependiendo de nuestro objetivo. Sin importar el tipo de transformacion que apliquen, todos los transformers siguen la convención de tener por lo menos dos métodos:\n",
    "* `.fit()` calcula los parámetros necesarios para realizar la transformación a partir de unos datos de entrada. Este método se ejecuta únicamente en los datos de entrenamiento para asegurarnos que los parámetros no contienen información de los datos de validación.\n",
    "* `.transform()` aplica la transformación a los datos.\n",
    "\n",
    "Veamos un ejemplo usando `StandardScaler`, un transformer que nos permite remover la media y escalar los datos para que tengan varianza de 1. Vamos a usarlo para normalizar los coordenadas de inicio del viaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30923835 -0.27478234]\n",
      " [-0.13589444  0.75675283]\n",
      " [ 0.24599071  0.58169127]\n",
      " ...\n",
      " [-0.19727957 -0.13002453]\n",
      " [-0.03955223 -0.08161096]\n",
      " [-0.11150857 -0.79791458]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transformer = StandardScaler()\n",
    "transformer.fit(\n",
    "    train_df[[\"pickup_longitude\", \"pickup_latitude\"]]\n",
    ")\n",
    "normed_array = transformer.transform(\n",
    "    val_df[[\"pickup_longitude\", \"pickup_latitude\"]]\n",
    ")\n",
    "print(normed_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformers\n",
    "A pesar de que `scikit-learn` ofrece varias operaciones para transformar datos, frecuentemente necesitamos crear transformaciones que son específicas a nuestro proyecto. Para esto vamos a aprender cómo implementar custom transformers.\n",
    "\n",
    "Todos los transformer custom deben heredar `BaseEstimator` y `TransformerMixin` para que tengan todas las funciones necesarias para conectarse a otros objetos de `sklearn`. Por convención de sklearn, los objetos usados para transformar datos siempre deben tener los métodos `.fit()` y `.transform()`. Ambos métodos reciben `X` y `y` para que se integren sin problemas a pipelines de `sklearn`. \n",
    "\n",
    "El método `.fit()` sirve para almacenar cantidades que vamos a usar durante la transformación de los datos y siempre debe retornar `self`. El método `.transform()` ejecuta la transformación y retorna los datos transformados. Ahora vamos a replicar el `StandardScaler` pero esta vez escribiéndolo como un transformer personalizado que no retorne un array sino un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PrimerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.mean = X.mean()\n",
    "        self.std = X.std()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return (X - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #1**\n",
    "\n",
    "Correr `.fit()` y `.transform()` para `PrimerTransformer` para las coordenadas de inicio del viaje y verificar que el resultado sea igual al del `StandardScaler`.\n",
    "\n",
    "De `PrimerTransformer` va a salir un DataFrame en lugar de un array pero los valores deben ser los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "primer_transformer = PrimerTransformer()\n",
    "primer_transformer.fit(train_df[['pickup_longitude', 'pickup_latitude']])\n",
    "val_normed_df = primer_transformer.transform(val_df[['pickup_longitude', 'pickup_latitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5897</th>\n",
       "      <td>-0.309238</td>\n",
       "      <td>-0.274782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253622</th>\n",
       "      <td>-0.135894</td>\n",
       "      <td>0.756752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971937</th>\n",
       "      <td>0.245991</td>\n",
       "      <td>0.581691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120472</th>\n",
       "      <td>0.176797</td>\n",
       "      <td>0.385864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520502</th>\n",
       "      <td>0.194096</td>\n",
       "      <td>0.182913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878521</th>\n",
       "      <td>-0.488949</td>\n",
       "      <td>-0.292409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749666</th>\n",
       "      <td>-0.565470</td>\n",
       "      <td>-1.408094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784550</th>\n",
       "      <td>-0.197279</td>\n",
       "      <td>-0.130024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106094</th>\n",
       "      <td>-0.039552</td>\n",
       "      <td>-0.081611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259025</th>\n",
       "      <td>-0.111509</td>\n",
       "      <td>-0.797914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361964 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pickup_longitude  pickup_latitude\n",
       "5897           -0.309238        -0.274782\n",
       "253622         -0.135894         0.756752\n",
       "971937          0.245991         0.581691\n",
       "120472          0.176797         0.385864\n",
       "520502          0.194096         0.182913\n",
       "...                  ...              ...\n",
       "878521         -0.488949        -0.292409\n",
       "749666         -0.565470        -1.408094\n",
       "784550         -0.197279        -0.130024\n",
       "106094         -0.039552        -0.081611\n",
       "259025         -0.111509        -0.797914\n",
       "\n",
       "[361964 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_normed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este [link](https://scikit-learn.org/stable/developers/develop.html) pueden encontrar más detalles de qué papel juegan los métodos `__init__`, `.fit()` y `.transform()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Fechas\n",
    "Ahora que sabemos cómo construir objetos para transformar datos, vamos a crear un transformer para crear variables como el día de la semana y la hora del momento en el que empieza el servicio. Como vimos la semana pasada en nuestro EDA, esa información puede ser relevante para determinar la duración del viaje.\n",
    "\n",
    "En nuestra transformación no debemos almacenar ningún dato para hacer las transformación entonces dejamos el método `.fit()` vacío. En `.transform()` extraemos los datos de fecha que nos interesan y retornamos un dataframe con las nuevas variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFechas(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        columna_fecha = pd.to_datetime(X[\"pickup_datetime\"])\n",
    "        fecha_df = pd.DataFrame()\n",
    "        # TODO: Crear columnas con dia de la semana y hora de recogida.\n",
    "        fecha_df['weekday'] = columna_fecha.dt.weekday\n",
    "        fecha_df['hour'] = columna_fecha.dt.hour\n",
    "        return fecha_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #2.1**\n",
    "\n",
    "Completar el codigo para extrar el día de la semana y la hora a partir de una fecha en pandas y los ponga en las columnas `weekday` y `hour`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515114</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120575</th>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570170</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54377</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594726</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         weekday  hour\n",
       "515114         3    21\n",
       "1120575        6    21\n",
       "570170         1    18\n",
       "54377          6    17\n",
       "594726         0    16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_fechas = TransformerFechas()\n",
    "fechas_df = transformer_fechas.fit_transform(train_df)\n",
    "fechas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Distancia\n",
    "También queremos crear una feature que nos ayude a medir la distancia entre el punto de origen y el punto de destino usando la longitud y la latitud en los datos. Nuevamente no tenemos que almacenar cantidades en nuestro método `.fit()` y calculamos la distancia entre los dos puntos usando la [distancia de Haversine](https://es.wikipedia.org/wiki/F%C3%B3rmula_del_semiverseno). En el código ya está implementada la función para calcular la distancia y no es necesario fijarse en los detalles de la implementación. Como pueden ver, nuestros transformers pueden incluir funciones adicionales que nos ayuden a calcular cantidades útiles para realizar la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDistancia(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_init = X[[\"pickup_latitude\", \"pickup_longitude\"]].to_numpy()\n",
    "        X_final = X[[\"dropoff_latitude\", \"dropoff_longitude\"]].to_numpy()\n",
    "\n",
    "        # Distancia de Haversine\n",
    "        # TODO: Calcular la variable distancia usando la funcion\n",
    "        # distancia de Haversine.\n",
    "        distancia = self.distancia_haversine(X_init=X_init, X_final=X_final)\n",
    "        distancia_df = pd.DataFrame()\n",
    "        distancia_df[\"distancia\"] = distancia\n",
    "        return distancia_df\n",
    "    \n",
    "    def distancia_haversine(self, X_init, X_final):\n",
    "        # Convertir de decimal a radianes\n",
    "        X_init = np.radians(X_init)\n",
    "        X_final = np.radians(X_final)\n",
    "\n",
    "        # Formula Haversine\n",
    "        dlat = X_final[:, 0] - X_init[:, 0] \n",
    "        dlon = X_final[:, 1] - X_init[:, 1]\n",
    "        a = np.sin(dlat / 2) ** 2 + np.cos(X_init[:, 0]) * np.cos(X_final[:, 0]) * np.sin(dlon / 2) ** 2\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "        return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.404355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.629826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.298386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.488963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distancia\n",
       "0   2.404355\n",
       "1   0.390267\n",
       "2   5.629826\n",
       "3   4.298386\n",
       "4   7.488963"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_dist = TransformerDistancia()\n",
    "distancias_df = transformer_dist.fit_transform(train_df)\n",
    "distancias_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #2.2**\n",
    "\n",
    "Calcular la distancia de Haversine usando el método que está implementado en la clase y almacenarlo en la variable distancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unión de transformers con Pipelines\n",
    "### Pipeline Numérico\n",
    "Ahora vamos a usar los objetos de `Pipeline` y `ColumnTransformer` para unir los transformers que ya hemos creado con otros disponibles en `sklearn` y lograr todas las transformaciones que queremos realizar a todos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ColumnTransformer` nos permite elegir las columnas sobre las que queremos aplicar una transformación cuando nos llegan columnas adicionales. En este caso queremos que al `TransformerDistancia` llegue únicamente `pickup_longitude`, `pickup_latitude`, `dropoff_longitude` y `dropoff_latitude`.\n",
    "\n",
    "Leyendo la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer) sabemos que debemos pasar una tupla con el nombre del transformer, la clase que define el transformer y las columnas sobre las que queremos aplicar la transformación. `ColumnTransformer` también nos permite definir qué se debe hacer con las columnas que no estamos transformando; en este caso elegimos pasarlas sin transformarlas `remainder=\"passthrough\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 {color: black;background-color: white;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 pre{padding: 0;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-toggleable {background-color: white;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-item {z-index: 1;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-parallel-item:only-child::after {width: 0;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-0a14ac57-57ff-4480-a85a-be23b46ee2e2\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"140c9675-1130-4d28-a01b-d4650fdc92c7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"140c9675-1130-4d28-a01b-d4650fdc92c7\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('transformer_dist', TransformerDistancia(),\n",
       "                                 ['pickup_longitude', 'pickup_latitude',\n",
       "                                  'dropoff_longitude', 'dropoff_latitude'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"250d55b9-b52a-486c-9f1d-20e92b61c074\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"250d55b9-b52a-486c-9f1d-20e92b61c074\">transformer_dist</label><div class=\"sk-toggleable__content\"><pre>['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5ad23b4c-76e5-4485-a05a-f027550aa0d8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5ad23b4c-76e5-4485-a05a-f027550aa0d8\">TransformerDistancia</label><div class=\"sk-toggleable__content\"><pre>TransformerDistancia()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a8628224-8ba3-4c99-9535-2a53c9bd311d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a8628224-8ba3-4c99-9535-2a53c9bd311d\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"92d640c2-7504-43c1-a022-0cb797e91a7d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"92d640c2-7504-43c1-a022-0cb797e91a7d\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('transformer_dist', TransformerDistancia(),\n",
       "                                 ['pickup_longitude', 'pickup_latitude',\n",
       "                                  'dropoff_longitude', 'dropoff_latitude'])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coord_cols = [\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\"\n",
    "]\n",
    "\n",
    "transformer_coord = ColumnTransformer(\n",
    "    [\n",
    "        (\"transformer_dist\", TransformerDistancia(), coord_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "display(transformer_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos nuestro transformer que realiza transformación usando las coordenadas y deja pasar columnas adicionales, vamos a usarlo para unirlo con la otra variable númerica que tenemos en el dataset—`passenger_count`— y normalizarlas usando `StandardScaler`. Para esto vamos a usar el objeto `Pipeline`.\n",
    "\n",
    "`Pipeline` [(documentación Pipeline)](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) nos permite concatenar transformaciones de `sklearn`. En este caso vamos a concatenar el `ColumnTransformer` que creamos con `TransformerDistancia` con el `StandardScaler`. Como `passenger_count` no estaba entre columnas que selecciona `transformer_coord`, esa columna pasa directamente a ser normalizada por el `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.25154928 -0.50616698]\n",
      " [-0.73141214  0.25385023]\n",
      " [ 0.51692963 -0.50616698]\n",
      " ...\n",
      " [-0.41058443 -0.50616698]\n",
      " [-0.3461049  -0.50616698]\n",
      " [ 1.33898968  0.25385023]]\n"
     ]
    }
   ],
   "source": [
    "num_cols = [\"passenger_count\"] + coord_cols\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"transformer_coord\", transformer_coord),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_num = num_pipeline.fit_transform(train_df[num_cols], y_train)\n",
    "print(X_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la función `display` podemos ver el diagrama del flujo que acabamos de crear. Por `TransformerDistancia` pasan las variables de longitud y latitud y por `passthrough` pasa cualquier columna que le pasemos al `ColumnTransformer` que no sean longitud o latitud—en este caso `passenger_count`. El último paso es aplicar un `StandardScaler` a la variable de distancia que sale de `TransformerDistancia` y a las variables que vienen de `passthrough`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 {color: black;background-color: white;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 pre{padding: 0;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-toggleable {background-color: white;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-estimator:hover {background-color: #d4ebff;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-item {z-index: 1;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-parallel-item:only-child::after {width: 0;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-f9f39310-081c-4601-a5d5-0673e5ee7dd0\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"99cf3254-0f8b-40fc-8bee-1502738830d9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"99cf3254-0f8b-40fc-8bee-1502738830d9\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('transformer_coord',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('transformer_dist',\n",
       "                                                  TransformerDistancia(),\n",
       "                                                  ['pickup_longitude',\n",
       "                                                   'pickup_latitude',\n",
       "                                                   'dropoff_longitude',\n",
       "                                                   'dropoff_latitude'])])),\n",
       "                ('scaler', StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c3404785-f5d6-4e51-8c4f-236caa97fc75\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c3404785-f5d6-4e51-8c4f-236caa97fc75\">transformer_coord: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('transformer_dist', TransformerDistancia(),\n",
       "                                 ['pickup_longitude', 'pickup_latitude',\n",
       "                                  'dropoff_longitude', 'dropoff_latitude'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"04888150-b90b-4701-9478-c1d89149bcb8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"04888150-b90b-4701-9478-c1d89149bcb8\">transformer_dist</label><div class=\"sk-toggleable__content\"><pre>['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d9fc34b8-6131-42e5-ba43-6420c098816c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d9fc34b8-6131-42e5-ba43-6420c098816c\">TransformerDistancia</label><div class=\"sk-toggleable__content\"><pre>TransformerDistancia()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"bd67627f-f2da-458d-9be2-bb0bdd57471d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"bd67627f-f2da-458d-9be2-bb0bdd57471d\">remainder</label><div class=\"sk-toggleable__content\"><pre>['passenger_count']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b30a8e46-f190-4d46-872e-9f0429813c02\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b30a8e46-f190-4d46-872e-9f0429813c02\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"052f1c71-9f36-427d-852d-caec21fc2861\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"052f1c71-9f36-427d-852d-caec21fc2861\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer_coord',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('transformer_dist',\n",
       "                                                  TransformerDistancia(),\n",
       "                                                  ['pickup_longitude',\n",
       "                                                   'pickup_latitude',\n",
       "                                                   'dropoff_longitude',\n",
       "                                                   'dropoff_latitude'])])),\n",
       "                ('scaler', StandardScaler())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(num_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Categórico\n",
    "Usaremos una lógica similar para las variables categóricas pero esta vez para concatenar el resultado de extraer variables temporales de la fecha de inicio del viaje con un `OneHotEncoder` para las variables categóricas de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3., 21.,  0.,  1.],\n",
       "       [ 6., 21.,  1.,  2.],\n",
       "       [ 1., 18.,  1.,  2.],\n",
       "       ...,\n",
       "       [ 6.,  2.,  0.,  3.],\n",
       "       [ 1., 23.,  1.,  1.],\n",
       "       [ 1.,  2.,  1.,  2.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "cat_cols = [\"vendor_id\", \"pickup_borough\", \"pickup_datetime\"]\n",
    "\n",
    "transformer_fechas = ColumnTransformer(\n",
    "    [\n",
    "        #TODO: Punto 1 de Checkpoint 3\n",
    "        (\"transformer_fechas\", TransformerFechas(), [\"pickup_datetime\"]),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    [\n",
    "        #TODO: Punto 2 de Checkpoint 3\n",
    "        (\"transformer_fechas\", transformer_fechas),\n",
    "        (\"ordinal_encoder\", OrdinalEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_cat = cat_pipeline.fit_transform(train_df[cat_cols])\n",
    "X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 {color: black;background-color: white;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 pre{padding: 0;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-toggleable {background-color: white;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-estimator:hover {background-color: #d4ebff;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-item {z-index: 1;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-parallel-item:only-child::after {width: 0;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-a4ef3121-9389-4cc5-96d7-ec3b8a365b79\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"165add79-a462-4be0-bd73-66b82c13d219\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"165add79-a462-4be0-bd73-66b82c13d219\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('transformer_fechas',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('transformer_fechas',\n",
       "                                                  TransformerFechas(),\n",
       "                                                  ['pickup_datetime'])])),\n",
       "                ('ordinal_encoder', OrdinalEncoder())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ecee6666-8c7b-4539-a647-7a7e8e6a3f45\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ecee6666-8c7b-4539-a647-7a7e8e6a3f45\">transformer_fechas: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('transformer_fechas', TransformerFechas(),\n",
       "                                 ['pickup_datetime'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cd25a803-dcbc-46ce-ac80-f3b2abba37e8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"cd25a803-dcbc-46ce-ac80-f3b2abba37e8\">transformer_fechas</label><div class=\"sk-toggleable__content\"><pre>['pickup_datetime']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f2c4b621-0b5c-4141-a29a-8d2e94c4e0f2\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f2c4b621-0b5c-4141-a29a-8d2e94c4e0f2\">TransformerFechas</label><div class=\"sk-toggleable__content\"><pre>TransformerFechas()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0e9ef60b-dc24-4590-8916-63fd91f29085\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0e9ef60b-dc24-4590-8916-63fd91f29085\">remainder</label><div class=\"sk-toggleable__content\"><pre>['vendor_id', 'pickup_borough']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"76eaa287-9e0b-4ff4-847a-91776d5d5818\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"76eaa287-9e0b-4ff4-847a-91776d5d5818\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e81a72a0-7e64-444e-a635-7b564676760b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e81a72a0-7e64-444e-a635-7b564676760b\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('transformer_fechas',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('transformer_fechas',\n",
       "                                                  TransformerFechas(),\n",
       "                                                  ['pickup_datetime'])])),\n",
       "                ('ordinal_encoder', OrdinalEncoder())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cat_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #3**\n",
    "\n",
    "1. Crear un `ColumnTransformer` llamado `transformer_fechas` que solo seleccione la variable `pickup_datetime` para aplicarle el `TransformerFechas`.\n",
    "2. Unir el `ColumnTransformer` del punto 1 con un `OrdinalEncoder` para transformar las variables que salen del `ColumnTransformer` de fechas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unión de Pipelines\n",
    "Por último, usaremos nuevamente el `ColumnTransformer` para determinar cuáles son las variables numéricas y las variables catégoricas en nuestros datos. Definiendo varios elementos en la lista que le pasamos al `ColumnTransformer` le hacemos saber a `sklearn` que queremos diferentes transformaciones para las columnas y al final queremos unirlas para que todas queden en un solo `numpy` array. En nuestro caso, unimos las columnas que resultan del preprocesamiento de las categóricas y del de las numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1085891, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = ColumnTransformer(\n",
    "    [\n",
    "        (\"num_pipeline\", num_pipeline, num_cols),\n",
    "        (\"cat_pipeline\", cat_pipeline, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_transformed = full_pipeline.fit_transform(train_df, y_train)\n",
    "print(X_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este diagrama podemos ver que ejecutamos las transformaciones por separado para las variables numéricas y las categóricas y al final las unimos para tener los datos en un array que le pasaremos al modelo al momento de entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 {color: black;background-color: white;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 pre{padding: 0;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-toggleable {background-color: white;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-estimator:hover {background-color: #d4ebff;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-item {z-index: 1;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-parallel-item:only-child::after {width: 0;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-2f7144e3-1f96-48f0-9a53-1d8e4ac29290\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4c6b4fed-9ab5-4dff-9ed7-31bf1dbe83be\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4c6b4fed-9ab5-4dff-9ed7-31bf1dbe83be\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                 Pipeline(steps=[('transformer_coord',\n",
       "                                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                                    transformers=[('transformer_dist',\n",
       "                                                                                   TransformerDistancia(),\n",
       "                                                                                   ['pickup_longitude',\n",
       "                                                                                    'pickup_latitude',\n",
       "                                                                                    'dropoff_longitude',\n",
       "                                                                                    'dropoff_latitude'])])),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['passenger_count', 'pickup_longitude',\n",
       "                                  'pickup_latitude', 'dropoff_longitude',\n",
       "                                  'dropoff_latitude']),\n",
       "                                ('cat_pipeline',\n",
       "                                 Pipeline(steps=[('transformer_fechas',\n",
       "                                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                                    transformers=[('transformer_fechas',\n",
       "                                                                                   TransformerFechas(),\n",
       "                                                                                   ['pickup_datetime'])])),\n",
       "                                                 ('ordinal_encoder',\n",
       "                                                  OrdinalEncoder())]),\n",
       "                                 ['vendor_id', 'pickup_borough',\n",
       "                                  'pickup_datetime'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"65c72c33-4723-4f61-a7eb-66c4f40323dc\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"65c72c33-4723-4f61-a7eb-66c4f40323dc\">num_pipeline</label><div class=\"sk-toggleable__content\"><pre>['passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"393c5d48-e517-4dd5-9388-c050f4b8e9ed\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"393c5d48-e517-4dd5-9388-c050f4b8e9ed\">transformer_coord: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('transformer_dist', TransformerDistancia(),\n",
       "                                 ['pickup_longitude', 'pickup_latitude',\n",
       "                                  'dropoff_longitude', 'dropoff_latitude'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cc221ab6-52a4-4fd5-bb60-ee430958a6a5\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"cc221ab6-52a4-4fd5-bb60-ee430958a6a5\">transformer_dist</label><div class=\"sk-toggleable__content\"><pre>['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"07670ce5-f883-42e1-af09-f37a6444442e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"07670ce5-f883-42e1-af09-f37a6444442e\">TransformerDistancia</label><div class=\"sk-toggleable__content\"><pre>TransformerDistancia()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3768c4a5-b6e0-438d-9028-1c689d19ccbd\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3768c4a5-b6e0-438d-9028-1c689d19ccbd\">remainder</label><div class=\"sk-toggleable__content\"><pre>['passenger_count']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2a756c6c-4338-4eb8-83c0-5db8d9e08621\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2a756c6c-4338-4eb8-83c0-5db8d9e08621\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"315eb708-ca7e-4ce6-99af-a64ec7734c81\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"315eb708-ca7e-4ce6-99af-a64ec7734c81\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c69f6a8d-8a09-42a5-81ed-a1399b1f839b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c69f6a8d-8a09-42a5-81ed-a1399b1f839b\">cat_pipeline</label><div class=\"sk-toggleable__content\"><pre>['vendor_id', 'pickup_borough', 'pickup_datetime']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1a72d5b0-deee-48a5-8ce6-8b5c6132347a\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1a72d5b0-deee-48a5-8ce6-8b5c6132347a\">transformer_fechas: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('transformer_fechas', TransformerFechas(),\n",
       "                                 ['pickup_datetime'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5752d675-09dc-4bc9-b680-61f608275bc7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5752d675-09dc-4bc9-b680-61f608275bc7\">transformer_fechas</label><div class=\"sk-toggleable__content\"><pre>['pickup_datetime']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a2a47c14-ee47-4d0c-8444-a0a40e29a869\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a2a47c14-ee47-4d0c-8444-a0a40e29a869\">TransformerFechas</label><div class=\"sk-toggleable__content\"><pre>TransformerFechas()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c2a4272c-512b-4c41-a486-4fb1d545271a\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c2a4272c-512b-4c41-a486-4fb1d545271a\">remainder</label><div class=\"sk-toggleable__content\"><pre>['vendor_id', 'pickup_borough']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ab2a69fa-34c0-4db6-ad3d-243683dffc63\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ab2a69fa-34c0-4db6-ad3d-243683dffc63\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2bd84318-dfb8-4737-974e-14a5add14181\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2bd84318-dfb8-4737-974e-14a5add14181\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                 Pipeline(steps=[('transformer_coord',\n",
       "                                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                                    transformers=[('transformer_dist',\n",
       "                                                                                   TransformerDistancia(),\n",
       "                                                                                   ['pickup_longitude',\n",
       "                                                                                    'pickup_latitude',\n",
       "                                                                                    'dropoff_longitude',\n",
       "                                                                                    'dropoff_latitude'])])),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['passenger_count', 'pickup_longitude',\n",
       "                                  'pickup_latitude', 'dropoff_longitude',\n",
       "                                  'dropoff_latitude']),\n",
       "                                ('cat_pipeline',\n",
       "                                 Pipeline(steps=[('transformer_fechas',\n",
       "                                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                                    transformers=[('transformer_fechas',\n",
       "                                                                                   TransformerFechas(),\n",
       "                                                                                   ['pickup_datetime'])])),\n",
       "                                                 ('ordinal_encoder',\n",
       "                                                  OrdinalEncoder())]),\n",
       "                                 ['vendor_id', 'pickup_borough',\n",
       "                                  'pickup_datetime'])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(full_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar Pipeline a Disco\n",
    "Además de tener una clara separación entre los métodos `.fit()` y `.transform()`, la ventaja de escribir todo nuestro proceso como un solo pipeline (`full_pipeline`) es que podemos guardar en disco el objeto que usamos para preprocesar. Esto es útil para tener todas las transformaciones definidas en un objeto al momento que queramos hacer reproducibles nuestras transformaciones para, por ejemplo, desplegar nuestro modelo.\n",
    "\n",
    "Creamos un contexto usando `open()` y usamos la función `dill.dump()` para guardar nuestro flujo de preprocesamiento en disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.settings['recurse'] = True\n",
    "\n",
    "with open(\"preprocesser.pkl\", \"wb\") as f:\n",
    "    dill.dump(full_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargar nuestro flujo, usamos la función `dill.load()`. Además verificamos que el resultado de las transformaciones con el flujo que teníamos en el notebook y el que cargamos desde el disco es idéntico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with open(\"preprocesser.pkl\", \"rb\") as f:\n",
    "    loaded_pipeline = dill.load(f)\n",
    "    \n",
    "X_loaded = loaded_pipeline.transform(train_df)\n",
    "print((X_loaded == X_transformed).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El bloque anterior debería imprimir `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #4**\n",
    "\n",
    "Guardar pipeline de preprocesamiento en un archivo y volver a cargarlo con éxito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn y MLflow\n",
    "En esta sección veremos como todos los modelos de `sklearn` tiene la misma API para entrenar todo tipo de modelos (en este caso de regresión). Veremos cómo usar los métodos `.fit()` y `.predict()`. Además veremos cómo usar MLflow para guardar métricas y parámetros de todos los modelos que corramos. **Si estás haciendo esta sección en el mismo notebook de la sección anterior, puedes saltar hasta Transformación de Datos.**\n",
    "\n",
    "Empezaremos cargando los datos y el preprocesador que construimos en la sección anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport dill\\nimport numpy as np\\nimport pandas as pd\\n\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.base import BaseEstimator, TransformerMixin\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque de código vamos a copiar los transformers de la sección anterior. Normalmente los importaríamos de un archivo .py por los dejaremos en el notebook por simplicidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass TransformerFechas(BaseEstimator, TransformerMixin):\\n    def fit(self, X, y=None):\\n        return self\\n    def transform(self, X, y=None):\\n        columna_fecha = pd.to_datetime(X[\"pickup_datetime\"])\\n        fecha_df = pd.DataFrame()\\n        fecha_df[\"weekday\"] = columna_fecha.dt.weekday\\n        fecha_df[\"hour\"] = columna_fecha.dt.hour\\n        return fecha_df\\n\\nclass TransformerDistancia(BaseEstimator, TransformerMixin):\\n    def fit(self, X, y=None):\\n        return self\\n\\n    def transform(self, X, y=None):\\n        X_init = X[[\"pickup_latitude\", \"pickup_longitude\"]].to_numpy()\\n        X_final = X[[\"dropoff_latitude\", \"dropoff_longitude\"]].to_numpy()\\n\\n        # Distancia de Haversine\\n        distancia = self.distancia_haversine(X_init=X_init, X_final=X_final)\\n        distancia_df = pd.DataFrame()\\n        distancia_df[\"distancia\"] = distancia\\n        return distancia_df\\n    \\n    def distancia_haversine(self, X_init, X_final):\\n        # Convertir de decimal a radianes\\n        X_init = np.radians(X_init)\\n        X_final = np.radians(X_final)\\n\\n        # haversine formula \\n        dlat = X_final[:, 0] - X_init[:, 0] \\n        dlon = X_final[:, 1] - X_init[:, 1]\\n        a = np.sin(dlat / 2) ** 2 + np.cos(X_init[:, 0]) * np.cos(X_final[:, 0]) * np.sin(dlon / 2) ** 2\\n        c = 2 * np.arcsin(np.sqrt(a))\\n        r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\\n        return c * r\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class TransformerFechas(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        columna_fecha = pd.to_datetime(X[\"pickup_datetime\"])\n",
    "        fecha_df = pd.DataFrame()\n",
    "        fecha_df[\"weekday\"] = columna_fecha.dt.weekday\n",
    "        fecha_df[\"hour\"] = columna_fecha.dt.hour\n",
    "        return fecha_df\n",
    "\n",
    "class TransformerDistancia(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_init = X[[\"pickup_latitude\", \"pickup_longitude\"]].to_numpy()\n",
    "        X_final = X[[\"dropoff_latitude\", \"dropoff_longitude\"]].to_numpy()\n",
    "\n",
    "        # Distancia de Haversine\n",
    "        distancia = self.distancia_haversine(X_init=X_init, X_final=X_final)\n",
    "        distancia_df = pd.DataFrame()\n",
    "        distancia_df[\"distancia\"] = distancia\n",
    "        return distancia_df\n",
    "    \n",
    "    def distancia_haversine(self, X_init, X_final):\n",
    "        # Convertir de decimal a radianes\n",
    "        X_init = np.radians(X_init)\n",
    "        X_final = np.radians(X_final)\n",
    "\n",
    "        # haversine formula \n",
    "        dlat = X_final[:, 0] - X_init[:, 0] \n",
    "        dlon = X_final[:, 1] - X_init[:, 1]\n",
    "        a = np.sin(dlat / 2) ** 2 + np.cos(X_init[:, 0]) * np.cos(X_final[:, 0]) * np.sin(dlon / 2) ** 2\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "        return c * r\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí cargamos los datos y el preprocesador entrenado de la sección anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = pd.read_csv(\"taxi-trip-duration.csv\")\\n# Limitar rango de datos\\ntiempo_minimo = 60 # 1 minuto\\ntiempo_maximo = 36000 # 10 horas\\ndata = data[\\n    (data[\"trip_duration\"] > tiempo_minimo) &\\n    (data[\"trip_duration\"] < tiempo_maximo)\\n]\\n\\ny = data[\"trip_duration\"]\\nselected_columns = [\\n    \\'vendor_id\\',\\n    \\'pickup_datetime\\',\\n    \\'passenger_count\\',\\n    \\'pickup_longitude\\',\\n    \\'pickup_latitude\\',\\n    \\'dropoff_longitude\\',\\n    \\'dropoff_latitude\\',\\n    \\'pickup_borough\\',\\n    \\'dropoff_borough\\'\\n]\\ninput_df = data[selected_columns]\\ntrain_df, val_df, y_train, y_val = train_test_split(input_df, y, random_state=0)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data = pd.read_csv(\"taxi-trip-duration.csv\")\n",
    "# Limitar rango de datos\n",
    "tiempo_minimo = 60 # 1 minuto\n",
    "tiempo_maximo = 36000 # 10 horas\n",
    "data = data[\n",
    "    (data[\"trip_duration\"] > tiempo_minimo) &\n",
    "    (data[\"trip_duration\"] < tiempo_maximo)\n",
    "]\n",
    "\n",
    "y = data[\"trip_duration\"]\n",
    "selected_columns = [\n",
    "    'vendor_id',\n",
    "    'pickup_datetime',\n",
    "    'passenger_count',\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude',\n",
    "    'pickup_borough',\n",
    "    'dropoff_borough'\n",
    "]\n",
    "input_df = data[selected_columns]\n",
    "train_df, val_df, y_train, y_val = train_test_split(input_df, y, random_state=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya no es necesario hacer `.fit()` para aplicar las transformaciones al dataframe de entrada porque toda la información quedó almacenada en el archivo `preprocesser.pkl` y se carga al usar `dill.load()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"preprocesser.pkl\", \"rb\") as f:\n",
    "    preprocessor = dill.load(f)\n",
    "\n",
    "X_train = preprocessor.transform(train_df)\n",
    "X_val = preprocessor.transform(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar Modelos\n",
    "### Baseline con `DummyRegressor`\n",
    "Una opción que nos ofrece `sklearn` es entrenar modelos dummy. Estos son modelos que predicen lo mismo para todos los casos (en este caso el promedio) y nos sirven como una medida de cuál es el rendimiento mínimo para un problema. Si por alguna razón nuestro modelo tiene peor desempeño que el modelo dummy, tenemos que revisar nuestro modelo porque probablemente tenemos errores en la implementación.\n",
    "\n",
    "En este caso vamos a usar el `DummyRegressor` que siempre predice la media de los datos de entrenamiento. La función `evaluar_predicciones` es una ayuda para poder calcular varias métricas de un modelo usando metricas incluídas de `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score, mean_squared_log_error\n",
    "\n",
    "def evaluar_predicciones(y_pred, y_true):\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_true)\n",
    "    mape = mean_absolute_percentage_error(y_pred=y_pred, y_true=y_true)\n",
    "    rmse = mean_squared_error(y_pred=y_pred, y_true=y_true, squared=False)\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MAPE: {mape}\")\n",
    "    print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "MAE: 468.61\n",
      "MAPE: 0.95585624685749\n",
      "RMSE: 683.1658889831872\n",
      "VALIDATION\n",
      "MAE: 468.42\n",
      "MAPE: 0.9567650882594899\n",
      "RMSE: 680.0030431781618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_model = DummyRegressor(strategy=\"mean\")\n",
    "dummy_model.fit(X_train, y_train)\n",
    "y_train_dummy = dummy_model.predict(X_train)\n",
    "y_val_dummy = dummy_model.predict(X_val)\n",
    "\n",
    "print(\"TRAIN\")\n",
    "evaluar_predicciones(y_pred=y_train_dummy, y_true=y_train)\n",
    "\n",
    "print(\"VALIDATION\")\n",
    "evaluar_predicciones(y_pred=y_val_dummy, y_true=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline con regresión lineal\n",
    "Otra buena medida es siempre empezar con un modelo lineal. Así tenemos una medida de cómo se desempeña un modelo sencillo.\n",
    "\n",
    "Algo para notar es que sin importar el modelo, los modelos de `sklearn` siempre siguen el mismo proceso. \n",
    "1. Inicializar modelo con la clase de `sklearn`. \n",
    "2. Ejecutar función `.fit(X_train, y_train)`. \n",
    "3. Ejecutar función `.predict(X)` para generar las predicciones.\n",
    "\n",
    "Esta consistencia en el proceso simplifica el uso de diferentes modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "MAE: 296.09\n",
      "MAPE: 0.5533021393418208\n",
      "RMSE: 487.0504325444076\n",
      "VALIDATION\n",
      "MAE: 295.55\n",
      "MAPE: 0.55406813955327\n",
      "RMSE: 529.0958979710375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#TODO: entrenar un modelo lineal con LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_train_linear = linear_model.predict(X_train)\n",
    "y_val_linear = linear_model.predict(X_val)\n",
    "\n",
    "print(\"TRAIN\")\n",
    "evaluar_predicciones(y_pred=y_train_linear, y_true=y_train)\n",
    "\n",
    "print(\"VALIDATION\")\n",
    "evaluar_predicciones(y_pred=y_val_linear, y_true=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #1**\n",
    "\n",
    "1. Entrenar un model de regresión linear usando LinearRergression de `scikit-learn`.\n",
    "2. Predecir valores del viaje para train (`y_train_linear`) y validación (`y_val_linear`)\n",
    "\n",
    "Las métricas del modelo deberían ser similares a las imagen de arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo comparar modelos más allá de un print? MLFlow 🙌\n",
    "Imprimiendo los resultados nos podemos dar cuenta del modelo con mejores resultados. Sin embargo, comparar los resultados usando `print` es difícil cuando el número de modelos empieza a crecer. Además idealmente queremos que todos los modelos queden guardados para poder retomarlos después. Para todo esto podemos usar MLflow.\n",
    "\n",
    "[MLflow](https://www.mlflow.org/) es una librería open-source que nos ayuda a manejar todo el ciclo de modelos de machine learning. En este caso vamos a ver cómo podemos usar MLflow para guardar resultados del desempeño de modelos para determinar cuál modelo es el mejor.\n",
    "\n",
    "Vamos a correr los mismos modelos que acabamos de comparar pero esta vez vamos a usar MLflow para ver los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mlflow.sklearn.autolog()` automáticamente nos ayuda a guardar varias métricas y parámetros del modelo. Sin embargo, no incluye valores para datos de validación. Para guardar métricas que no se incluyen en `.autolog` vamos a usar la función `mlflow.log_metric` dentro del *context manager* de `run`.\n",
    "\n",
    "Vamos primero a usar el modelo dummy y vamos a poner `run_name=\"dummy\"` para poder verlo con el nombre correcto en MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"dummy\") as run:\n",
    "    dummy_model = DummyRegressor(strategy=\"mean\")\n",
    "    dummy_model.fit(X_train, y_train)\n",
    "    y_pred_val = dummy_model.predict(X_val)\n",
    "    \n",
    "    val_mae = mean_absolute_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_rmse = mean_squared_error(y_pred=y_pred_val, y_true=y_val, squared=False)\n",
    "    val_mape = mean_absolute_percentage_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_r2 = r2_score(y_pred=y_pred_val, y_true=y_val)\n",
    "\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mape\", val_mape)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez termine de correr esta celda debemos abrir la interfaz de MLflow para ver los resultados. Deberíamos encontrar una nueva carpeta llamada `mlruns` en la ubicación donde corrió este notebook. Una vez estemos en la carpeta donde está `mlruns`, debemos ir a un terminal a esa ubicación y ejecutamos el comando.\n",
    "```\n",
    "mlflow ui\n",
    "```\n",
    "Ahí nos debería salir el mensaje de que está iniciando un servidor y dar la ruta para acceder. (normalmente la ruta es http://127.0.0.1:5000). Copiamos esa dirección en un navegador y ahí ya deberíamos ver la interfaz de MLflow.\n",
    "<img src='../imgs/image1.png'>\n",
    "\n",
    "En la interfaz de MLflow estarán los modelos que corramos usando MLflow y podemos filtrar u ordenar por métricas o parámetros que consideramos importantes. En general, con la interfaz de MLflow tenemos una base de datos de modelos que podemos analizar fácilmente.\n",
    "\n",
    "Además, si hacemos click un alguna de las *runs* (click en la columna Start Time) podemos ver que tenemos los datos más detallados y los *artifacts* de cada *run*. Los *artifacts* pueden ser todo tipo de archivos (por ejemplo imágenes y CSVs) que nos ayudan a guardar lo relevante de cada caso como el modelo o el ambiente de conda desde el que corrimos el modelo.\n",
    "<img src='../imgs/image2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora corramos nuevamente la regresión lineal para que quede registrada en MLflow. En este caso vamos a guardar nuestro preprocesador que quede asociado a cada *run* usando `.log_artifact`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"linear_regression\") as run:\n",
    "    #TODO: Hacer fit a un modelo lineal\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train, y_train)\n",
    "    y_pred_val = linear_model.predict(X_val)\n",
    "    \n",
    "    val_mae = mean_absolute_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_rmse = mean_squared_error(y_pred=y_pred_val, y_true=y_val, squared=False)\n",
    "    val_mape = mean_absolute_percentage_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_r2 = r2_score(y_pred=y_pred_val, y_true=y_val)\n",
    "\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mape\", val_mape)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)\n",
    "    mlflow.log_artifact(\"preprocesser.pkl\")\n",
    "    \n",
    "    with open(\"lr_model.pkl\", \"wb\") as f:\n",
    "        dill.dump(linear_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 758.5223093 , 1027.50977341,  631.91801717, ...,  516.49415498,\n",
       "        978.32991323, 1081.93453691])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758.5223092982421"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred_val)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos la regresión lineal y el modelo dummy en MLflow, vamos a probar con un modelo más complejo como el Random Forest. Por ahora vamos a dejar los parámetros por defecto que trae la clase `RandomForestRegressor` excepto `n_jobs` que lo vamos a poner con el parámetro `n_jobs=2`. Poner `n_jobs=2` hace que el modelo corra en paralelo en 2 procesadores.\n",
    "Entrenar el random forest puede tomar algunos minutos así que es un buen momento para resolver cualquier duda o tomar un descanso y estirar las piernas :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/10/24 21:59:34 ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpfjgb1zr1\\model\\model.pkl, flavor: sklearn)\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\ASUS\\anaconda3\\envs\\factored\\lib\\site-packages\\mlflow\\utils\\environment.py\", line 212, in infer_pip_requirements\n",
      "    return _infer_requirements(model_uri, flavor)\n",
      "  File \"D:\\Users\\ASUS\\anaconda3\\envs\\factored\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 263, in _infer_requirements\n",
      "    modules = _capture_imported_modules(model_uri, flavor)\n",
      "  File \"D:\\Users\\ASUS\\anaconda3\\envs\\factored\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 221, in _capture_imported_modules\n",
      "    _run_command(\n",
      "  File \"D:\\Users\\ASUS\\anaconda3\\envs\\factored\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py\", line 173, in _run_command\n",
      "    raise MlflowException(msg)\n",
      "mlflow.exceptions.MlflowException: Encountered an unexpected error while running ['D:\\\\Users\\\\ASUS\\\\anaconda3\\\\envs\\\\factored\\\\python.exe', 'D:\\\\Users\\\\ASUS\\\\anaconda3\\\\envs\\\\factored\\\\lib\\\\site-packages\\\\mlflow\\\\utils\\\\_capture_modules.py', '--model-path', 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\tmpfjgb1zr1\\\\model\\\\model.pkl', '--flavor', 'sklearn', '--output-file', 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Local\\\\Temp\\\\tmpbftb1jic\\\\imported_modules.txt', '--sys-path', '[\"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\Data Challenge 365 Fem - DataCamp\\\\\\\\Factored_DSFem_workshops\\\\\\\\session2\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\git\\\\\\\\ext\\\\\\\\gitdb\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\\\\\\\\python38.zip\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\\\\\\\\DLLs\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\\\\\\\\lib\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\", \"\", \"C:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Python\\\\\\\\Python38\\\\\\\\site-packages\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\\\\\\\\lib\\\\\\\\site-packages\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\win32\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\win32\\\\\\\\lib\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\Pythonwin\", \"C:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Python\\\\\\\\Python38\\\\\\\\site-packages\\\\\\\\IPython\\\\\\\\extensions\", \"C:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\.ipython\", \"D:\\\\\\\\Users\\\\\\\\ASUS\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\factored\\\\\\\\lib\\\\\\\\site-packages\\\\\\\\gitdb\\\\\\\\ext\\\\\\\\smmap\"]']\n",
      "exit status: 1\n",
      "stdout: \n",
      "stderr: Traceback (most recent call last):\r\n",
      "  File \"D:\\Users\\ASUS\\anaconda3\\envs\\factored\\lib\\site-packages\\mlflow\\utils\\_capture_modules.py\", line 125, in <module>\r\n",
      "    main()\r\n",
      "  File \"D:\\Users\\ASUS\\anaconda3\\envs\\factored\\lib\\site-packages\\mlflow\\utils\\_capture_modules.py\", line 118, in main\r\n",
      "    importlib.import_module(f\"mlflow.{flavor}\")._load_pyfunc(model_path)\r\n",
      "  File \"D:\\Users\\ASUS\\anaconda3\\envs\\factored\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 415, in _load_pyfunc\r\n",
      "    return _load_model_from_local_file(path=path, serialization_format=serialization_format)\r\n",
      "  File \"D:\\Users\\ASUS\\anaconda3\\envs\\factored\\lib\\site-packages\\mlflow\\sklearn\\__init__.py\", line 369, in _load_model_from_local_file\r\n",
      "    return pickle.load(f)\r\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 671, in sklearn.tree._tree.Tree.__setstate__\r\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 706, in sklearn.tree._tree.Tree._resize_c\r\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 41, in sklearn.tree._utils.safe_realloc\r\n",
      "MemoryError: could not allocate 10937720 bytes\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "with mlflow.start_run(run_name=\"random_forest\") as run:\n",
    "    #TODO: Hacer fit a un modelo random forest\n",
    "    rf_model = RandomForestRegressor(n_jobs=2)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_val = rf_model.predict(X_val)\n",
    "    \n",
    "    val_mae = mean_absolute_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_rmse = mean_squared_error(y_pred=y_pred_val, y_true=y_val, squared=False)\n",
    "    val_mape = mean_absolute_percentage_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_r2 = r2_score(y_pred=y_pred_val, y_true=y_val)\n",
    "\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mape\", val_mape)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)\n",
    "    mlflow.log_artifact(\"preprocesser.pkl\")\n",
    "    \n",
    "    with open(\"rf_model.pkl\", \"wb\") as f:\n",
    "        dill.dump(rf_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint #2**\n",
    "\n",
    "Entrenar un modelo lineal y un random forest y verificar las métricas de validación en MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esas herramientas puedes buscar más [modelos de regresión de sklearn](https://scikit-learn.org/stable/supervised_learning.html) o mejorar los hiperparámetros de los modelos que usamos para intentar mejorar las métricas que obtuvimos hasta el momento. Incluso librerías como [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn) o [LightGBM](https://lightgbm.readthedocs.io/en/latest/Python-API.html#scikit-learn-api) ofrecen la opción de crear modelos con la API de sklearn. A pesar de que cada modelo puede usar técnicas muy diferentes, el código va a ser casi idéntico gracias a la consistencia en la API de `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras\n",
    "## Transformers Adicionales\n",
    "### Transformer Velocidades\n",
    "Vamos a crear un transformer para calcular la velocidad promedio en cada zona (borough) de Nueva York y asignarle esa velocidad a cada viaje.\n",
    "\n",
    "Para calcular la velocidad necesitamos el tiempo que se demora el viaje. Como esta es nuestra variable dependiente, debemos tener en cuenta que solo podemos usar los datos de train porque, en principio, no hemos observado los datos de validation. Al calcular las velocidades para cada zona con los datos que llegan a `.fit()` evitamos el data leakage porque garantizamos que no estamos usando los tiempos de viaje de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerVelocidad(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y):\n",
    "        X_init = X[[\"pickup_latitude\", \"pickup_longitude\"]].to_numpy()\n",
    "        X_final = X[[\"dropoff_latitude\", \"dropoff_longitude\"]].to_numpy()\n",
    "\n",
    "        # Distancia de Haversine\n",
    "        distancia = self.distancia_haversine(X_init=X_init, X_final=X_final)\n",
    "        \n",
    "        velocidad_df = pd.DataFrame()\n",
    "        tiempo_en_horas = y.to_numpy() / 3600\n",
    "        velocidad_df[\"velocidad\"] = distancia / tiempo_en_horas\n",
    "        velocidad_df[\"pickup_borough\"] = X[\"pickup_borough\"]\n",
    "        velocidad_borough = velocidad_df.groupby(\"pickup_borough\")[\"velocidad\"].mean()\n",
    "        self.velocidad_borough = velocidad_borough.to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        velocidad_df = pd.DataFrame()\n",
    "        velocidad_df[\"velocidad\"] = X[\"pickup_borough\"].map(self.velocidad_borough)\n",
    "        return velocidad_df\n",
    "    \n",
    "    def distancia_haversine(self, X_init, X_final):\n",
    "        # Convertir de decimal a radianes\n",
    "        X_init = np.radians(X_init)\n",
    "        X_final = np.radians(X_final)\n",
    "\n",
    "        # Formula de Haversine\n",
    "        dlat = X_final[:, 0] - X_init[:, 0] \n",
    "        dlon = X_final[:, 1] - X_init[:, 1]\n",
    "        a = (np.sin(dlat / 2) ** 2) + np.cos(X_init[:, 0]) * np.cos(X_final[:, 0]) * (np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        r = 6371 # Radio de la tierra en kilómetros\n",
    "        return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>velocidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515114</th>\n",
       "      <td>14.440112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120575</th>\n",
       "      <td>14.416140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570170</th>\n",
       "      <td>14.416140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54377</th>\n",
       "      <td>14.440112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594726</th>\n",
       "      <td>14.440112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         velocidad\n",
       "515114   14.440112\n",
       "1120575  14.416140\n",
       "570170   14.416140\n",
       "54377    14.440112\n",
       "594726   14.440112"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_velocidades = TransformerVelocidad()\n",
    "velocidades_df = transformer_velocidades.fit_transform(train_df, y_train)\n",
    "velocidades_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando con XGBoost y LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics_mlflow(y_pred_val, y_val):\n",
    "    val_mae = mean_absolute_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_rmse = mean_squared_error(y_pred=y_pred_val, y_true=y_val, squared=False)\n",
    "    val_mape = mean_absolute_percentage_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_r2 = r2_score(y_pred=y_pred_val, y_true=y_val)\n",
    "\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mape\", val_mape)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "mlflow.lightgbm.autolog()\n",
    "with mlflow.start_run(run_name=\"lgbm\") as run:\n",
    "    lgbm_model = LGBMRegressor()\n",
    "    lgbm_model.fit(X_train, y_train)\n",
    "    y_pred_val = lgbm_model.predict(X_val)\n",
    "    log_metrics_mlflow(y_pred_val, y_val)\n",
    "    mlflow.log_artifact(\"preprocesser.pkl\")\n",
    "    \n",
    "    with open(\"lgbm_model.pkl\", \"wb\") as f:\n",
    "        dill.dump(lgbm_model, f)\n",
    "    mlflow.log_artifact(\"lgbm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "with mlflow.start_run(run_name=\"xgboost\") as run:\n",
    "    xgb_model = XGBRegressor()\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred_val = xgb_model.predict(X_val)\n",
    "    log_metrics_mlflow(y_pred_val, y_val)\n",
    "    mlflow.log_artifact(\"preprocesser.pkl\")\n",
    "    \n",
    "    with open(\"xgb_model.pkl\", \"wb\") as f:\n",
    "        dill.dump(xgb_model, f)\n",
    "    mlflow.log_artifact(\"xgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
